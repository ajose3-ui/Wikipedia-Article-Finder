{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajose3-ui/Wikipedia-Article-Finder/blob/main/WIKIPROJECT_THING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this if you want to save the generated CSVs to your drive:"
      ],
      "metadata": {
        "id": "fplaj7XbpZY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lhFSRXkk8gJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8937c2b6-63c8-4b8a-ba96-da5e55f6996c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install these so that everything works properly:"
      ],
      "metadata": {
        "id": "75LFKT9tplhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install textblob vaderSentiment textstat\n",
        "!pip install itables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "5vChMDPsXFAI",
        "outputId": "a70fd7cd-ec7e-4406-cdef-0e2b22c8e6f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.12)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2026.1.4)\n",
            "Requirement already satisfied: itables in /usr/local/lib/python3.12/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following tool may help you find articles. Please keep in mind that it may not always be accurate."
      ],
      "metadata": {
        "id": "tDu45yFyyYSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "\n",
        "def search_wikipedia_multiple(query, top_n=3):\n",
        "    \"\"\"\n",
        "    Search Wikipedia, get top 20 results, randomly sample 3 for variety.\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"list\": \"search\",\n",
        "        \"srsearch\": query,\n",
        "        \"srlimit\": 10,  # Get top 20 results\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        data = r.json()\n",
        "\n",
        "        all_results = []\n",
        "        for item in data.get(\"query\", {}).get(\"search\", []):\n",
        "            all_results.append({\n",
        "                \"title\": item[\"title\"],\n",
        "                \"snippet\": item.get(\"snippet\", \"\")\n",
        "            })\n",
        "\n",
        "        # Randomly sample 3 from the results\n",
        "        if len(all_results) >= top_n:\n",
        "            return random.sample(all_results, top_n)\n",
        "        else:\n",
        "            return all_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching Wikipedia: {e}\")\n",
        "        return []\n",
        "\n",
        "def get_conceptnet_related(query, limit=15):\n",
        "    \"\"\"\n",
        "    Get related concepts from ConceptNet API.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        encoded_query = query.replace(' ', '_').lower()\n",
        "        url = f\"http://api.conceptnet.io/query?node=/c/en/{encoded_query}&limit=100\"\n",
        "\n",
        "        r = requests.get(url, timeout=30)\n",
        "\n",
        "        if r.status_code != 200:\n",
        "            return []\n",
        "\n",
        "        data = r.json()\n",
        "\n",
        "        related_concepts = set()\n",
        "\n",
        "        for edge in data.get(\"edges\", []):\n",
        "            weight = edge.get(\"weight\", 0)\n",
        "\n",
        "            if weight < 1.0:\n",
        "                continue\n",
        "\n",
        "            start = edge.get(\"start\", {})\n",
        "            end = edge.get(\"end\", {})\n",
        "\n",
        "            for node in [start, end]:\n",
        "                label = node.get(\"label\", \"\")\n",
        "                language = node.get(\"language\", \"\")\n",
        "                node_term = node.get(\"term\", \"\")\n",
        "\n",
        "                if language == \"en\":\n",
        "                    if not label and node_term:\n",
        "                        term_parts = node_term.split('/')\n",
        "                        if len(term_parts) >= 3:\n",
        "                            label = term_parts[-1].replace('_', ' ')\n",
        "\n",
        "                    if label:\n",
        "                        clean_label = label.replace(\"_\", \" \").strip()\n",
        "                        if (clean_label.lower() != query.lower() and\n",
        "                            len(clean_label) > 2 and\n",
        "                            clean_label not in related_concepts):\n",
        "                            related_concepts.add(clean_label)\n",
        "\n",
        "        result = sorted(list(related_concepts))[:limit]\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing ConceptNet: {e}\")\n",
        "        return []\n",
        "\n",
        "def make_wikipedia_link(title):\n",
        "    \"\"\"\n",
        "    Create a clickable HTML link to a Wikipedia article.\n",
        "    \"\"\"\n",
        "    url_title = title.replace(' ', '_')\n",
        "    url = f\"https://en.wikipedia.org/wiki/{url_title}\"\n",
        "    return f'<a href=\"{url}\" target=\"_blank\">{title}</a>'\n",
        "\n",
        "def get_see_also_links(article_title, max_links=10):\n",
        "    \"\"\"\n",
        "    Extract links from See Also section.\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    parse_params = {\n",
        "        \"action\": \"parse\",\n",
        "        \"page\": article_title,\n",
        "        \"prop\": \"sections|wikitext\",\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=parse_params, headers=HEADERS, timeout=30)\n",
        "        data = r.json()\n",
        "\n",
        "        if \"parse\" not in data:\n",
        "            return []\n",
        "\n",
        "        wikitext = data[\"parse\"].get(\"wikitext\", {}).get(\"*\", \"\")\n",
        "\n",
        "        section_pattern = r\"==\\s*See also\\s*==(.*?)(?:==|$)\"\n",
        "        section_match = re.search(section_pattern, wikitext, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "        if not section_match:\n",
        "            return []\n",
        "\n",
        "        see_also_text = section_match.group(1)\n",
        "        links = re.findall(r'\\[\\[([^]|]+)(?:\\|[^]]+)?\\]\\]', see_also_text)\n",
        "\n",
        "        clean_links = []\n",
        "        for link in links:\n",
        "            if not link.startswith(('Category:', 'File:', 'Image:', 'Wikipedia:')):\n",
        "                clean_links.append(link)\n",
        "\n",
        "        return clean_links[:max_links]\n",
        "\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def get_filtered_links_from_article(article_title, max_links=12):\n",
        "    \"\"\"\n",
        "    Get conceptual links from the article.\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    links_params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": article_title,\n",
        "        \"prop\": \"links\",\n",
        "        \"pllimit\": 300,\n",
        "        \"plnamespace\": 0,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=links_params, headers=HEADERS, timeout=30)\n",
        "        data = r.json()\n",
        "        page = next(iter(data.get(\"query\", {}).get(\"pages\", {}).values()))\n",
        "\n",
        "        if \"links\" not in page:\n",
        "            return []\n",
        "\n",
        "        all_links = [link[\"title\"] for link in page[\"links\"]]\n",
        "\n",
        "        conceptual_keywords = [\n",
        "            'theory', 'philosophy', 'studies', 'criticism', 'ism',\n",
        "            'epistemology', 'methodology', 'approach', 'framework',\n",
        "            'perspective', 'analysis', 'research', 'science'\n",
        "        ]\n",
        "\n",
        "        exclude_patterns = [\n",
        "            r'^\\d{4}$',\n",
        "            r'List of',\n",
        "            r'Index of',\n",
        "            r'^[A-Z]{2,4}$',\n",
        "            r'University',\n",
        "            r'Press$',\n",
        "            r'Publishing',\n",
        "            r'Books$',\n",
        "            r'ISBN'\n",
        "        ]\n",
        "\n",
        "        filtered = []\n",
        "        for link in all_links:\n",
        "            if any(re.search(pattern, link) for pattern in exclude_patterns):\n",
        "                continue\n",
        "\n",
        "            if any(keyword in link.lower() for keyword in conceptual_keywords):\n",
        "                filtered.append(link)\n",
        "\n",
        "        if len(filtered) > max_links:\n",
        "            return random.sample(filtered, max_links)\n",
        "        return filtered\n",
        "\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def get_category_siblings(article_title, max_results=10):\n",
        "    \"\"\"\n",
        "    Get other articles in the same meaningful categories.\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    cat_params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": article_title,\n",
        "        \"prop\": \"categories\",\n",
        "        \"cllimit\": 50,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=cat_params, headers=HEADERS, timeout=30)\n",
        "        cat_data = r.json()\n",
        "        page = next(iter(cat_data.get(\"query\", {}).get(\"pages\", {}).values()))\n",
        "        categories = [cat[\"title\"] for cat in page.get(\"categories\", [])]\n",
        "\n",
        "        skip_terms = ['stub', 'articles', 'pages', 'wikipedia', 'template',\n",
        "                     'all ', 'cs1', 'webarchive', 'coordinates', 'commons',\n",
        "                     'use dmy', 'use mdy', 'living', 'year', 'century']\n",
        "\n",
        "        meaningful_cats = []\n",
        "        for cat in categories:\n",
        "            if not any(skip in cat.lower() for skip in skip_terms):\n",
        "                meaningful_cats.append(cat)\n",
        "\n",
        "        all_siblings = []\n",
        "\n",
        "        for category in meaningful_cats[:3]:\n",
        "            member_params = {\n",
        "                \"action\": \"query\",\n",
        "                \"list\": \"categorymembers\",\n",
        "                \"cmtitle\": category,\n",
        "                \"cmlimit\": 20,\n",
        "                \"cmnamespace\": 0,\n",
        "                \"format\": \"json\"\n",
        "            }\n",
        "\n",
        "            r = requests.get(url, params=member_params, headers=HEADERS, timeout=30)\n",
        "            member_data = r.json()\n",
        "\n",
        "            for member in member_data.get(\"query\", {}).get(\"categorymembers\", []):\n",
        "                title = member[\"title\"]\n",
        "                if title != article_title and title not in all_siblings:\n",
        "                    all_siblings.append(title)\n",
        "\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        if len(all_siblings) > max_results:\n",
        "            return random.sample(all_siblings, max_results)\n",
        "        return all_siblings\n",
        "\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def explore_topic_multiple_paths(query):\n",
        "    \"\"\"\n",
        "    Get related topics from multiple sources and pathways.\n",
        "    \"\"\"\n",
        "    wiki_results = search_wikipedia_multiple(query, top_n=3)\n",
        "    conceptnet_related = get_conceptnet_related(query, limit=12)\n",
        "\n",
        "    pathways = []\n",
        "\n",
        "    for i, result in enumerate(wiki_results):\n",
        "        article_title = result[\"title\"]\n",
        "\n",
        "        pathway = {\n",
        "            \"title\": article_title,\n",
        "            \"see_also\": get_see_also_links(article_title, 8),\n",
        "            \"related_concepts\": get_filtered_links_from_article(article_title, 10),\n",
        "            \"category_siblings\": get_category_siblings(article_title, 8)\n",
        "        }\n",
        "\n",
        "        pathways.append(pathway)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    return {\n",
        "        \"wikipedia_matches\": [r[\"title\"] for r in wiki_results],\n",
        "        \"pathways\": pathways,\n",
        "        \"conceptnet_alternatives\": conceptnet_related\n",
        "    }\n",
        "\n",
        "def create_smart_search_explorer():\n",
        "\n",
        "    topic_input = widgets.Text(\n",
        "        value='feminist theory',\n",
        "        placeholder='Enter a topic',\n",
        "        description='Topic:',\n",
        "        style={'description_width': '100px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    )\n",
        "\n",
        "    search_button = widgets.Button(\n",
        "        description='Explore Topic',\n",
        "        button_style='info',\n",
        "        layout=widgets.Layout(width='200px', height='40px')\n",
        "    )\n",
        "\n",
        "    output = widgets.Output()\n",
        "\n",
        "    def on_search_clicked(b):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            query = topic_input.value.strip()\n",
        "\n",
        "            if not query:\n",
        "                print(\"Please enter a topic.\")\n",
        "                return\n",
        "\n",
        "            print(\"TOPIC EXPLORATION\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Exploring: '{query}'\")\n",
        "            print(\"=\"*70)\n",
        "            print(\"\\nAnalyzing multiple pathways (30-40 seconds)...\\n\")\n",
        "\n",
        "            results = explore_topic_multiple_paths(query)\n",
        "\n",
        "            # Build HTML output with clickable links\n",
        "            html_output = \"<div style='font-family: monospace;'>\"\n",
        "\n",
        "            # Wikipedia matches\n",
        "            html_output += \"<h3>WIKIPEDIA ARTICLES FOUND</h3>\"\n",
        "            html_output += \"<hr>\"\n",
        "            if results[\"wikipedia_matches\"]:\n",
        "                html_output += \"<ol>\"\n",
        "                for match in results[\"wikipedia_matches\"]:\n",
        "                    html_output += f\"<li>{make_wikipedia_link(match)}</li>\"\n",
        "                html_output += \"</ol>\"\n",
        "            else:\n",
        "                html_output += \"<p>No Wikipedia articles found.</p>\"\n",
        "\n",
        "            # Pathways\n",
        "            for i, pathway in enumerate(results[\"pathways\"], 1):\n",
        "                html_output += f\"<h3>PATHWAY {i}: Based on '{pathway['title']}'</h3>\"\n",
        "                html_output += \"<hr>\"\n",
        "\n",
        "                if pathway[\"see_also\"]:\n",
        "                    html_output += \"<h4>Editor-curated related topics:</h4>\"\n",
        "                    html_output += \"<ol>\"\n",
        "                    for topic in pathway[\"see_also\"]:\n",
        "                        html_output += f\"<li>{make_wikipedia_link(topic)}</li>\"\n",
        "                    html_output += \"</ol>\"\n",
        "\n",
        "                if pathway[\"related_concepts\"]:\n",
        "                    html_output += \"<h4>Related concepts from article:</h4>\"\n",
        "                    html_output += \"<ol>\"\n",
        "                    for topic in pathway[\"related_concepts\"]:\n",
        "                        html_output += f\"<li>{make_wikipedia_link(topic)}</li>\"\n",
        "                    html_output += \"</ol>\"\n",
        "\n",
        "                if pathway[\"category_siblings\"]:\n",
        "                    html_output += \"<h4>Similar topics (same categories):</h4>\"\n",
        "                    html_output += \"<ol>\"\n",
        "                    for topic in pathway[\"category_siblings\"]:\n",
        "                        html_output += f\"<li>{make_wikipedia_link(topic)}</li>\"\n",
        "                    html_output += \"</ol>\"\n",
        "\n",
        "            # ConceptNet alternatives\n",
        "            if results[\"conceptnet_alternatives\"]:\n",
        "                html_output += \"<h3>ALTERNATIVE EXPLORATION ANGLES</h3>\"\n",
        "                html_output += \"<hr>\"\n",
        "                html_output += \"<p>Related concepts from semantic knowledge graph:</p>\"\n",
        "                html_output += \"<ol>\"\n",
        "                for concept in results[\"conceptnet_alternatives\"]:\n",
        "                    html_output += f\"<li>{make_wikipedia_link(concept)}</li>\"\n",
        "                html_output += \"</ol>\"\n",
        "\n",
        "            html_output += \"<hr>\"\n",
        "            html_output += \"<p><strong>Exploration complete. Click any link to open the Wikipedia article.</strong></p>\"\n",
        "            html_output += \"</div>\"\n",
        "\n",
        "            display(HTML(html_output))\n",
        "\n",
        "    search_button.on_click(on_search_clicked)\n",
        "\n",
        "    ui = widgets.VBox([\n",
        "        widgets.HTML(\"<h2>Multi-Path Topic Explorer</h2>\"),\n",
        "        widgets.HTML(\"<p>Discovers related topics from Wikipedia and semantic knowledge graphs.</p>\"),\n",
        "        topic_input,\n",
        "        search_button,\n",
        "        output\n",
        "    ])\n",
        "\n",
        "    display(ui)\n",
        "\n",
        "create_smart_search_explorer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "048ceffcf80f492588eec520ae966731",
            "cf83073b81ca4e0e8a8d9174bc2cb491",
            "66df35dedb7f43a69f3188599b479b1e",
            "0e7d37256e9741e1952e7f75305cc129",
            "35dfc69df4314ce9a64e5921479feef7",
            "01ab5073a5a9416bb8cc5b16d08ac6e1",
            "428688f2104540d9870e5b5245c420c9",
            "322e067c93d9410e97547a4bad525740",
            "a3a0013a494b4544a38dc25826c2d94a",
            "6f40db68760744ee9c1b1a2fede81e8b",
            "4d317205deff476696e6ead863d6e317",
            "206b32e4904d48659150bef141089478",
            "68638704b1bb49278ef2ba99448eabc6",
            "c34e8d43237640be82a341cd8a6d0889",
            "24e7bfd1627240d4b47f333c658b0fdc",
            "6fc690dd3c9e4f3ebb45b0e1d6702f89"
          ]
        },
        "cellView": "form",
        "id": "OcVETTEw606Q",
        "outputId": "a4cfa091-5188-4d6f-bb6c-86364f32c813"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>Multi-Path Topic Explorer</h2>'), HTML(value='<p>Discovers related topics from …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "048ceffcf80f492588eec520ae966731"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search for topics that intrest you:"
      ],
      "metadata": {
        "id": "CU8MR-qFptNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from urllib.parse import quote\n",
        "import time\n",
        "import re\n",
        "from IPython.display import display\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import textstat\n",
        "\n",
        "EMAIL = \"amjose05@gmail.com\" #@param {type:\"string\"}\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": f\"Wikiproject_article_finder/1.0 (Educational research; {EMAIL}; Python/requests)\"\n",
        "}\n",
        "\n",
        "SEARCH_QUERY = \"feminist theory\" #@param {type:\"string\"}\n",
        "MAX_ARTICLES = \"10\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  MAX_ARTICLES = int(MAX_ARTICLES)\n",
        "except (ValueError, TypeError):\n",
        "  MAX_ARTICLES = None\n",
        "\n",
        "LANG = \"en\"\n",
        "REQUEST_DELAY = 0.03\n",
        "CHECKPOINT_INTERVAL = 100\n",
        "MAX_WORKERS = 3\n",
        "\n",
        "def search_wikipedia_articles(query, max_articles=None):\n",
        "    \"\"\"Search Wikipedia for articles containing specific keywords.\"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    print(f\"Searching for articles related to: '{query}'\")\n",
        "\n",
        "    titles = []\n",
        "    offset = 0\n",
        "\n",
        "    while True:\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"list\": \"search\",\n",
        "            \"srsearch\": query,\n",
        "            \"srlimit\": 50,\n",
        "            \"sroffset\": offset,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            print(\"Non-JSON response, retrying...\")\n",
        "            time.sleep(2)\n",
        "            continue\n",
        "\n",
        "        data = r.json()\n",
        "        results = data.get(\"query\", {}).get(\"search\", [])\n",
        "\n",
        "        if not results:\n",
        "            break\n",
        "\n",
        "        print(f\"  Found {len(results)} results at offset {offset}\")\n",
        "\n",
        "        for result in results:\n",
        "            title = result[\"title\"]\n",
        "            titles.append(title)\n",
        "\n",
        "            if max_articles and len(titles) >= max_articles:\n",
        "                print(f\"✓ Reached limit of {max_articles} articles\")\n",
        "                return titles[:max_articles]\n",
        "\n",
        "        if \"continue\" in data:\n",
        "            offset = data[\"continue\"][\"sroffset\"]\n",
        "            time.sleep(REQUEST_DELAY)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(f\"✓ Total articles found: {len(titles)}\")\n",
        "    return titles\n",
        "\n",
        "def get_all_article_data(title):\n",
        "    \"\"\"Fetch ALL data for an article in one go to minimize API calls.\"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": title,\n",
        "        \"redirects\": True,\n",
        "        \"prop\": \"revisions|extracts|images|categories\",\n",
        "        \"rvprop\": \"content|timestamp\",\n",
        "        \"rvslots\": \"main\",\n",
        "        \"explaintext\": True,\n",
        "        \"exlimit\": 1,\n",
        "        \"imlimit\": 500,\n",
        "        \"cllimit\": 500,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return None\n",
        "\n",
        "        data = r.json()\n",
        "        page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "\n",
        "        wikitext = page.get(\"revisions\", [{}])[0].get(\"slots\", {}).get(\"main\", {}).get(\"*\", \"\")\n",
        "        plaintext = page.get(\"extract\", \"\")\n",
        "        timestamp = page.get(\"revisions\", [{}])[0].get(\"timestamp\", \"\")\n",
        "        images = len(page.get(\"images\", []))\n",
        "        categories = len(page.get(\"categories\", []))\n",
        "\n",
        "        return {\n",
        "            \"wikitext\": wikitext,\n",
        "            \"plaintext\": plaintext,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"images\": images,\n",
        "            \"categories\": categories\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {title}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_from_cached_data(title, cached_data):\n",
        "    \"\"\"Run all analyses using cached data\"\"\"\n",
        "    if not cached_data:\n",
        "        return get_empty_metrics()\n",
        "\n",
        "    wikitext = cached_data[\"wikitext\"]\n",
        "    plaintext = cached_data[\"plaintext\"]\n",
        "    timestamp = cached_data[\"timestamp\"]\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # Basic metadata\n",
        "    days_since_edit = 0\n",
        "    if timestamp:\n",
        "        last_edit = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        days_since_edit = round((datetime.now(timezone.utc).replace(tzinfo=None) - last_edit).days)\n",
        "\n",
        "    word_count = len(plaintext.split()) if plaintext else 0\n",
        "    citation_needed_count = wikitext.lower().count(\"citation needed\")\n",
        "\n",
        "    metrics[\"Days Since Last Edit\"] = days_since_edit\n",
        "    metrics[\"Word Count\"] = word_count\n",
        "    metrics[\"Citations Needed\"] = citation_needed_count\n",
        "    metrics[\"Images\"] = cached_data[\"images\"]\n",
        "    metrics[\"Categories\"] = cached_data[\"categories\"]\n",
        "\n",
        "    # Source Quality Analysis\n",
        "    source_metrics = analyze_source_quality_from_text(wikitext)\n",
        "    metrics.update(source_metrics)\n",
        "\n",
        "    # Neutrality Detection\n",
        "    neutrality_metrics = analyze_neutrality_from_text(plaintext)\n",
        "    metrics.update(neutrality_metrics)\n",
        "\n",
        "    # Reading Level\n",
        "    readability_metrics = analyze_readability_from_text(plaintext)\n",
        "    metrics.update(readability_metrics)\n",
        "\n",
        "    # Sentiment\n",
        "    sentiment_metrics = detect_sentiment_bias_from_text(plaintext)\n",
        "    metrics.update(sentiment_metrics)\n",
        "\n",
        "    # Citations\n",
        "    metrics[\"Citations\"] = get_citation_count_from_text(wikitext)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def analyze_source_quality_from_text(wikitext):\n",
        "    \"\"\"Analyze source quality from wikitext - works with all citation formats\"\"\"\n",
        "\n",
        "    # Count different citation template types\n",
        "    cite_patterns = {\n",
        "        \"journal\": r'{{cite journal',\n",
        "        \"book\": r'{{cite book',\n",
        "        \"web\": r'{{cite web',\n",
        "        \"news\": r'{{cite news',\n",
        "    }\n",
        "\n",
        "    source_types = {k: len(re.findall(v, wikitext, re.IGNORECASE)) for k, v in cite_patterns.items()}\n",
        "    total_typed_sources = sum(source_types.values())\n",
        "\n",
        "    # Extract years from ALL citation formats\n",
        "    years = []\n",
        "    current_year = datetime.now().year\n",
        "\n",
        "    # Method 1: Years from {{cite}} templates\n",
        "    citation_blocks = re.findall(r'{{cite[^}]+}}', wikitext, re.IGNORECASE | re.DOTALL)\n",
        "    for block in citation_blocks:\n",
        "        year_matches = re.findall(r'\\|(?:year|date|publication-date|access-date)\\s*=\\s*[^\\d]*(\\d{4})', block, re.IGNORECASE)\n",
        "        for year_str in year_matches:\n",
        "            year = int(year_str)\n",
        "            if 1800 <= year <= current_year:\n",
        "                years.append(year)\n",
        "                break  # Only take first year per citation\n",
        "\n",
        "    # Method 2: Years from <ref> tags\n",
        "    ref_blocks = re.findall(r'<ref[^>]*>(.*?)</ref>', wikitext, re.IGNORECASE | re.DOTALL)\n",
        "    for ref in ref_blocks:\n",
        "        # Look for years in common formats: (2020), 2020., \"2020\"\n",
        "        year_patterns = [\n",
        "            r'\\((\\d{4})\\)',           # (2020)\n",
        "            r'[,\\s](\\d{4})[,\\.\\s]',   # , 2020, or . 2020.\n",
        "            r'\"(\\d{4})\"',              # \"2020\"\n",
        "            r'(\\d{4})-\\d{2}-\\d{2}',   # 2020-01-15 (date format)\n",
        "        ]\n",
        "\n",
        "        for pattern in year_patterns:\n",
        "            year_matches = re.findall(pattern, ref)\n",
        "            if year_matches:\n",
        "                year = int(year_matches[0])\n",
        "                if 1800 <= year <= current_year:\n",
        "                    years.append(year)\n",
        "                    break  # Only take first year per ref\n",
        "\n",
        "    # Method 3: Years from {{sfn}}, {{harvnb}}, {{harv}} templates\n",
        "    short_footnotes = re.findall(r'{{(?:sfn|harvnb|harv)[^}]*\\|[^}]*?(\\d{4})', wikitext, re.IGNORECASE)\n",
        "    for year_str in short_footnotes:\n",
        "        year = int(year_str)\n",
        "        if 1800 <= year <= current_year:\n",
        "            years.append(year)\n",
        "\n",
        "    # Method 4: Years from {{citation}} templates (alternative to {{cite}})\n",
        "    citation_templates = re.findall(r'{{citation[^}]+}}', wikitext, re.IGNORECASE | re.DOTALL)\n",
        "    for block in citation_templates:\n",
        "        year_matches = re.findall(r'\\|(?:year|date|publication-date)\\s*=\\s*[^\\d]*(\\d{4})', block, re.IGNORECASE)\n",
        "        for year_str in year_matches:\n",
        "            year = int(year_str)\n",
        "            if 1800 <= year <= current_year:\n",
        "                years.append(year)\n",
        "                break\n",
        "\n",
        "    # Remove duplicates while preserving order (in case same source cited multiple times)\n",
        "    # We keep duplicates because multiple citations of same year is valid\n",
        "    # But we can deduplicate if needed - for now keep all\n",
        "\n",
        "    # Calculate metrics\n",
        "    recent_sources = len([y for y in years if current_year - y <= 5]) if years else 0\n",
        "    avg_source_age = (current_year - sum(years) / len(years)) if years else 0\n",
        "\n",
        "    quality_score = 0\n",
        "\n",
        "    if total_typed_sources > 0:\n",
        "        scholarly_ratio = (source_types[\"journal\"] + source_types[\"book\"]) / total_typed_sources\n",
        "        quality_score += scholarly_ratio * 50\n",
        "\n",
        "    source_diversity = len([v for v in source_types.values() if v > 0])\n",
        "    quality_score += source_diversity * 10\n",
        "\n",
        "    if avg_source_age < 10:\n",
        "        quality_score += 25\n",
        "    elif avg_source_age < 20:\n",
        "        quality_score += 15\n",
        "\n",
        "    return {\n",
        "        \"Journal Sources\": source_types[\"journal\"],\n",
        "        \"Book Sources\": source_types[\"book\"],\n",
        "        \"Web Sources\": source_types[\"web\"],\n",
        "        \"News Sources\": source_types[\"news\"],\n",
        "        \"Avg Source Age\": round(avg_source_age, 1),\n",
        "        \"Recent Sources (5yr)\": recent_sources,\n",
        "        \"Source Quality Score\": round(min(quality_score, 100), 1)\n",
        "    }\n",
        "\n",
        "def analyze_neutrality_from_text(text):\n",
        "    \"\"\"Detect POV/bias issues\"\"\"\n",
        "    if not text:\n",
        "        return {\n",
        "            \"Hedging Words\": 0,\n",
        "            \"Peacock Words\": 0,\n",
        "            \"Weasel Words\": 0,\n",
        "            \"Value Judgments\": 0,\n",
        "            \"Neutrality Score\": 100\n",
        "        }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    peacock_terms = [\n",
        "        \"legendary\", \"iconic\", \"acclaimed\", \"prestigious\", \"renowned\",\n",
        "        \"celebrated\", \"world-class\", \"premier\", \"leading\", \"foremost\",\n",
        "        \"groundbreaking\", \"seminal\", \"pivotal\", \"revolutionary\", \"extraordinary\",\n",
        "        \"remarkable\", \"outstanding\", \"exceptional\", \"unparalleled\", \"best\"\n",
        "    ]\n",
        "    peacock_count = sum(text_lower.count(term) for term in peacock_terms)\n",
        "\n",
        "    weasel_patterns = [\n",
        "        r'\\bsome (people|experts|scholars|critics|observers|say|believe)',\n",
        "        r'\\bmany (believe|argue|claim|suggest|think|feel)',\n",
        "        r'\\bit (is said|has been said|is believed|is widely|is commonly)',\n",
        "        r'\\bmost (people|experts|scholars)',\n",
        "        r'\\bwidely (regarded|considered|accepted|believed)',\n",
        "        r'\\boften (considered|regarded|viewed)',\n",
        "        r'\\bgenerally (accepted|believed|considered)',\n",
        "    ]\n",
        "    weasel_count = sum(len(re.findall(pattern, text_lower)) for pattern in weasel_patterns)\n",
        "\n",
        "    hedging_words = [\"perhaps\", \"possibly\", \"maybe\", \"might\", \"could\", \"may\", \"seemingly\"]\n",
        "    hedging_count = sum(text_lower.count(word) for word in hedging_words)\n",
        "\n",
        "    value_words = [\n",
        "        \"unfortunately\", \"fortunately\", \"clearly\", \"obviously\", \"naturally\",\n",
        "        \"of course\", \"undoubtedly\", \"certainly\", \"arguably\", \"notably\",\n",
        "        \"importantly\", \"surprisingly\", \"interestingly\", \"regrettably\"\n",
        "    ]\n",
        "    value_count = sum(text_lower.count(word) for word in value_words)\n",
        "\n",
        "    word_count = len(text.split())\n",
        "    neutrality_score = 100\n",
        "\n",
        "    if word_count > 0:\n",
        "        neutrality_score -= (peacock_count / word_count * 1000) * 10\n",
        "        neutrality_score -= (weasel_count / word_count * 1000) * 15\n",
        "        neutrality_score -= (value_count / word_count * 1000) * 8\n",
        "\n",
        "    neutrality_score = max(0, min(100, neutrality_score))\n",
        "\n",
        "    return {\n",
        "        \"Hedging Words\": hedging_count,\n",
        "        \"Peacock Words\": peacock_count,\n",
        "        \"Weasel Words\": weasel_count,\n",
        "        \"Value Judgments\": value_count,\n",
        "        \"Neutrality Score\": round(neutrality_score, 1)\n",
        "    }\n",
        "\n",
        "def analyze_readability_from_text(text):\n",
        "    \"\"\"Calculate reading level\"\"\"\n",
        "    if not text or len(text) < 100:\n",
        "        return {\n",
        "            \"Flesch-Kincaid Grade\": 0,\n",
        "            \"Reading Level\": \"Unknown\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        flesch_grade = textstat.flesch_kincaid_grade(text)\n",
        "        flesch_ease = textstat.flesch_reading_ease(text)\n",
        "\n",
        "        if flesch_ease >= 90:\n",
        "            level = \"Elementary (5th grade)\"\n",
        "        elif flesch_ease >= 80:\n",
        "            level = \"Middle School (6-7th)\"\n",
        "        elif flesch_ease >= 70:\n",
        "            level = \"High School (8-9th)\"\n",
        "        elif flesch_ease >= 60:\n",
        "            level = \"High School (10-12th)\"\n",
        "        elif flesch_ease >= 50:\n",
        "            level = \"College\"\n",
        "        elif flesch_ease >= 30:\n",
        "            level = \"College Graduate\"\n",
        "        else:\n",
        "            level = \"Professional/Academic\"\n",
        "\n",
        "        return {\n",
        "            \"Flesch-Kincaid Grade\": round(flesch_grade, 1),\n",
        "            \"Reading Level\": level\n",
        "        }\n",
        "    except:\n",
        "        return {\n",
        "            \"Flesch-Kincaid Grade\": 0,\n",
        "            \"Reading Level\": \"Error\"\n",
        "        }\n",
        "\n",
        "def detect_sentiment_bias_from_text(text):\n",
        "    \"\"\"Detect sentiment bias\"\"\"\n",
        "    if not text:\n",
        "        return {\n",
        "            \"Polarity\": 0,\n",
        "            \"Subjectivity\": 0,\n",
        "            \"VADER Compound\": 0,\n",
        "            \"Sentiment\": \"Neutral\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        blob = TextBlob(text)\n",
        "        polarity = blob.sentiment.polarity\n",
        "        subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        vader_scores = analyzer.polarity_scores(text)\n",
        "\n",
        "        if abs(polarity) < 0.1 and subjectivity < 0.3:\n",
        "            sentiment = \"Neutral & Objective\"\n",
        "        elif abs(polarity) < 0.1:\n",
        "            sentiment = \"Neutral but Subjective\"\n",
        "        elif polarity > 0.2:\n",
        "            sentiment = \"Positive Bias Detected\"\n",
        "        elif polarity < -0.2:\n",
        "            sentiment = \"Negative Bias Detected\"\n",
        "        else:\n",
        "            sentiment = \"Slight Bias\"\n",
        "\n",
        "        return {\n",
        "            \"Polarity\": round(polarity, 3),\n",
        "            \"Subjectivity\": round(subjectivity, 3),\n",
        "            \"VADER Compound\": round(vader_scores['compound'], 3),\n",
        "            \"Sentiment\": sentiment\n",
        "        }\n",
        "    except:\n",
        "        return {\n",
        "            \"Polarity\": 0,\n",
        "            \"Subjectivity\": 0,\n",
        "            \"VADER Compound\": 0,\n",
        "            \"Sentiment\": \"Error\"\n",
        "        }\n",
        "\n",
        "def get_citation_count_from_text(wikitext):\n",
        "    \"\"\"Count citations from wikitext\"\"\"\n",
        "    if not wikitext:\n",
        "        return 0\n",
        "\n",
        "    named_refs = set()\n",
        "    unnamed_count = 0\n",
        "    ref_pattern = r'<ref(?:\\s+[^>]*)?>'\n",
        "    all_refs = re.findall(ref_pattern, wikitext, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    for ref in all_refs:\n",
        "        if ref.strip().endswith('/>'):\n",
        "            continue\n",
        "        name_match = re.search(r'name\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', ref, re.IGNORECASE)\n",
        "        if name_match:\n",
        "            named_refs.add(name_match.group(1))\n",
        "        else:\n",
        "            unnamed_count += 1\n",
        "\n",
        "    ref_count = len(named_refs) + unnamed_count\n",
        "\n",
        "    sfn_count = len(re.findall(r'\\{\\{sfn[a-z]*\\|', wikitext, re.IGNORECASE))\n",
        "    harv_count = len(re.findall(r'\\{\\{harv[a-z]*\\|', wikitext, re.IGNORECASE))\n",
        "    r_count = len(re.findall(r'\\{\\{rp?\\|', wikitext, re.IGNORECASE))\n",
        "    efn_count = len(re.findall(r'\\{\\{efn[a-z]*\\|', wikitext, re.IGNORECASE))\n",
        "\n",
        "    footnote_count = sfn_count + efn_count\n",
        "    return max(ref_count, footnote_count, harv_count, r_count)\n",
        "\n",
        "def get_remaining_data(title):\n",
        "    \"\"\"Get data that requires separate API calls\"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    sections = \"\"\n",
        "    try:\n",
        "        params = {\n",
        "            \"action\": \"parse\",\n",
        "            \"page\": title,\n",
        "            \"prop\": \"sections\",\n",
        "            \"redirects\": 1,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            parse_data = r.json().get(\"parse\", {})\n",
        "            if parse_data:\n",
        "                section_list = parse_data.get(\"sections\", [])\n",
        "                sections = \", \".join(s[\"line\"] for s in section_list)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    talk_page_size = 0\n",
        "    try:\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"titles\": f\"Talk:{title}\",\n",
        "            \"redirects\": True,\n",
        "            \"prop\": \"revisions\",\n",
        "            \"rvprop\": \"size\",\n",
        "            \"rvlimit\": 1,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            data = r.json()\n",
        "            pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "            page = next(iter(pages.values()), {})\n",
        "            if int(page.get(\"pageid\", -1)) > 0:\n",
        "                talk_page_size = page.get(\"revisions\", [{}])[0].get(\"size\", 0)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    num_editors, recent_edits = 0, 0\n",
        "    try:\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"titles\": title,\n",
        "            \"redirects\": True,\n",
        "            \"prop\": \"revisions\",\n",
        "            \"rvprop\": \"timestamp|user\",\n",
        "            \"rvlimit\": 500,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            data = r.json()\n",
        "            pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "            page = next(iter(pages.values()), {})\n",
        "            revisions = page.get(\"revisions\", [])\n",
        "\n",
        "            unique_editors = set()\n",
        "            one_year_ago = datetime.now(timezone.utc) - timedelta(days=365)\n",
        "\n",
        "            for rev in revisions:\n",
        "                user = rev.get(\"user\", \"\")\n",
        "                if user:\n",
        "                    unique_editors.add(user)\n",
        "                timestamp_str = rev.get(\"timestamp\", \"\")\n",
        "                if timestamp_str:\n",
        "                    timestamp = datetime.strptime(timestamp_str, \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=timezone.utc)\n",
        "                    if timestamp >= one_year_ago:\n",
        "                        recent_edits += 1\n",
        "\n",
        "            num_editors = len(unique_editors)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    views = 0\n",
        "    try:\n",
        "        end = datetime.now(timezone.utc).replace(tzinfo=None)\n",
        "        start = end - timedelta(days=90)\n",
        "        encoded_title = quote(title.replace(' ', '_'))\n",
        "        pv_url = (\n",
        "            f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/\"\n",
        "            f\"en.wikipedia/all-access/user/\"\n",
        "            f\"{encoded_title}/daily/\"\n",
        "            f\"{start:%Y%m%d}/{end:%Y%m%d}\"\n",
        "        )\n",
        "        r = requests.get(pv_url, headers=HEADERS, timeout=30)\n",
        "        if r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            data = r.json()\n",
        "            views = sum(d[\"views\"] for d in data.get(\"items\", []))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        \"Section Names\": sections,\n",
        "        \"Talk Page Size\": talk_page_size,\n",
        "        \"Total Editors\": num_editors,\n",
        "        \"Edits Last Year\": recent_edits,\n",
        "        \"Last 3 Months Views\": views\n",
        "    }\n",
        "\n",
        "def get_empty_metrics():\n",
        "    \"\"\"Return empty metrics dict for failed articles\"\"\"\n",
        "    return {\n",
        "        \"Days Since Last Edit\": 0,\n",
        "        \"Word Count\": 0,\n",
        "        \"Section Names\": \"\",\n",
        "        \"Citations\": 0,\n",
        "        \"Citations Needed\": 0,\n",
        "        \"Images\": 0,\n",
        "        \"Categories\": 0,\n",
        "        \"Total Editors\": 0,\n",
        "        \"Edits Last Year\": 0,\n",
        "        \"Talk Page Size\": 0,\n",
        "        \"Last 3 Months Views\": 0,\n",
        "        \"Journal Sources\": 0,\n",
        "        \"Book Sources\": 0,\n",
        "        \"Web Sources\": 0,\n",
        "        \"News Sources\": 0,\n",
        "        \"Avg Source Age\": 0,\n",
        "        \"Recent Sources (5yr)\": 0,\n",
        "        \"Source Quality Score\": 0,\n",
        "        \"Hedging Words\": 0,\n",
        "        \"Peacock Words\": 0,\n",
        "        \"Weasel Words\": 0,\n",
        "        \"Value Judgments\": 0,\n",
        "        \"Neutrality Score\": 0,\n",
        "        \"Flesch-Kincaid Grade\": 0,\n",
        "        \"Reading Level\": \"Unknown\",\n",
        "        \"Polarity\": 0,\n",
        "        \"Subjectivity\": 0,\n",
        "        \"VADER Compound\": 0,\n",
        "        \"Sentiment\": \"Unknown\"\n",
        "    }\n",
        "\n",
        "def process_single_article(title):\n",
        "    \"\"\"Process a single article - to be run in parallel\"\"\"\n",
        "    try:\n",
        "        cached_data = get_all_article_data(title)\n",
        "        metrics = analyze_from_cached_data(title, cached_data)\n",
        "        remaining = get_remaining_data(title)\n",
        "        metrics.update(remaining)\n",
        "        metrics[\"Article\"] = title\n",
        "\n",
        "        time.sleep(REQUEST_DELAY)\n",
        "        return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {title}: {e}\")\n",
        "        empty = get_empty_metrics()\n",
        "        empty[\"Article\"] = title\n",
        "        return empty\n",
        "\n",
        "# ============================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Searching Wikipedia for: '{SEARCH_QUERY}'\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "articles = search_wikipedia_articles(SEARCH_QUERY, MAX_ARTICLES)\n",
        "\n",
        "if not articles:\n",
        "    print(\"\\nNo articles found.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Processing {len(articles)} articles with {MAX_WORKERS} parallel workers...\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "rows = []\n",
        "start_time = time.time()\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    future_to_article = {executor.submit(process_single_article, title): title for title in articles}\n",
        "\n",
        "    for i, future in enumerate(as_completed(future_to_article), 1):\n",
        "        article = future_to_article[future]\n",
        "        try:\n",
        "            result = future.result()\n",
        "            rows.append(result)\n",
        "            print(f\"[{i}/{len(articles)}] Completed: {article}\")\n",
        "\n",
        "            if i % CHECKPOINT_INTERVAL == 0:\n",
        "                df_checkpoint = pd.DataFrame(rows)\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                checkpoint_file = f\"{SEARCH_QUERY.replace(' ', '_')}_{timestamp}_checkpoint.csv\"\n",
        "                df_checkpoint.to_csv(checkpoint_file, index=False)\n",
        "                elapsed = time.time() - start_time\n",
        "                remaining_time = (elapsed / i) * (len(articles) - i)\n",
        "                print(f\"Checkpoint saved: {checkpoint_file}\")\n",
        "                print(f\"Elapsed: {elapsed/60:.1f}min | Estimated remaining: {remaining_time/60:.1f}min\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed: {article} - {e}\")\n",
        "\n",
        "# ============================================\n",
        "# REORDER COLUMNS AND DISPLAY WITH QGRID\n",
        "# ============================================\n",
        "\n",
        "if rows:\n",
        "    df_unordered = pd.DataFrame(rows)\n",
        "\n",
        "    # Define column order\n",
        "    column_order = [\n",
        "        # Basic info\n",
        "        \"Article\",\n",
        "        \"Last 3 Months Views\",\n",
        "        \"Word Count\",\n",
        "        \"Talk Page Size\",\n",
        "        \"Days Since Last Edit\",\n",
        "        \"Edits Last Year\",\n",
        "        \"Total Editors\",\n",
        "        \"Images\",\n",
        "        \"Citations\",\n",
        "        \"Citations Needed\",\n",
        "\n",
        "        # Source quality\n",
        "        \"Journal Sources\",\n",
        "        \"Book Sources\",\n",
        "        \"Web Sources\",\n",
        "        \"News Sources\",\n",
        "        \"Avg Source Age\",\n",
        "        \"Recent Sources (5yr)\",\n",
        "        \"Source Quality Score\",\n",
        "\n",
        "        # Neutrality and bias\n",
        "        \"Hedging Words\",\n",
        "        \"Peacock Words\",\n",
        "        \"Weasel Words\",\n",
        "        \"Value Judgments\",\n",
        "        \"Neutrality Score\",\n",
        "\n",
        "        # Readability\n",
        "        \"Flesch-Kincaid Grade\",\n",
        "        \"Reading Level\",\n",
        "\n",
        "        # Sentiment\n",
        "        \"Polarity\",\n",
        "        \"Subjectivity\",\n",
        "        \"VADER Compound\",\n",
        "        \"Sentiment\",\n",
        "\n",
        "        # End columns\n",
        "        \"Categories\",\n",
        "        \"Section Names\"\n",
        "    ]\n",
        "\n",
        "    # Reorder (only include columns that exist)\n",
        "    df = df_unordered[[col for col in column_order if col in df_unordered.columns]]\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{SEARCH_QUERY.replace(' ', '_')}_{MAX_ARTICLES}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    # Try to save to Google Drive\n",
        "    try:\n",
        "        drive_filename = f\"/content/drive/MyDrive/{SEARCH_QUERY.replace(' ', '_')}_{MAX_ARTICLES}.csv\"\n",
        "        df.to_csv(drive_filename, index=False)\n",
        "        print(f\"Saved to Google Drive: {drive_filename}\")\n",
        "    except:\n",
        "        print(\"Google Drive not mounted, saved locally only\")\n",
        "\n",
        "    elapsed_total = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Successfully saved {len(df)} articles to: {filename}\")\n",
        "    print(f\"Total time: {elapsed_total/60:.1f} minutes ({elapsed_total/len(df):.2f}s per article)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # ============================================\n",
        "    # DISPLAY WITH ITABLES (MORE RELIABLE)\n",
        "    # ============================================\n",
        "\n",
        "    from itables import init_notebook_mode, show\n",
        "    init_notebook_mode(all_interactive=True)\n",
        "\n",
        "    print(\"Interactive Data Table\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"How to use:\")\n",
        "    print(\"SEARCH: Use the search box to filter across all columns\")\n",
        "    print(\"SORT: Click column headers to sort (shift+click for multi-column)\")\n",
        "    print(\"COLUMNS: Click 'Column visibility' button to show/hide columns\")\n",
        "    print(\"PAGES: Use dropdown to change rows per page (10/25/50/100)\")\n",
        "    print(\"EXPORT: Click 'CSV' or 'Excel' to download\")\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "\n",
        "    # Show interactive table\n",
        "    show(df,\n",
        "        scrollX=True,\n",
        "        scrollY=\"600px\",\n",
        "        paging=True,\n",
        "        lengthMenu=[10, 25, 50, 100],\n",
        "        pageLength=25,\n",
        "        buttons=['copy', 'csv', 'excel', 'colvis'],\n",
        "        order=[[1, 'desc']],  # Sort by \"Last 3 Months Views\" descending by default\n",
        "        columnDefs=[{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
        "    )\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Summary Statistics\")\n",
        "    print(f\"{'='*60}\")\n",
        "    numeric_cols = ['Last 3 Months Views', 'Word Count', 'Talk Page Size', 'Citations',\n",
        "                   'Days Since Last Edit', 'Source Quality Score', 'Neutrality Score',\n",
        "                   'Flesch-Kincaid Grade', 'Polarity', 'Subjectivity']\n",
        "    available_cols = [col for col in numeric_cols if col in df.columns]\n",
        "    print(df[available_cols].describe().round(1))\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo data to save\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EWoXcCZHU-UO",
        "outputId": "f6a4fe98-69d3-4559-acb2-1d2fe70be3a6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Searching Wikipedia for: 'feminist theory'\n",
            "============================================================\n",
            "Searching for articles related to: 'feminist theory'\n",
            "  Found 50 results at offset 0\n",
            "✓ Reached limit of 10 articles\n",
            "\n",
            "============================================================\n",
            "Processing 10 articles with 3 parallel workers...\n",
            "============================================================\n",
            "\n",
            "[1/10] Completed: Feminist legal theory\n",
            "[2/10] Completed: Feminist political theory\n",
            "[3/10] Completed: Feminist film theory\n",
            "[4/10] Completed: Feminist literary criticism\n",
            "[5/10] Completed: Toward a Feminist Theory of the State\n",
            "[6/10] Completed: Feminist theory\n",
            "[7/10] Completed: Feminist sociology\n",
            "[8/10] Completed: Third-wave feminism\n",
            "[9/10] Completed: Feminism\n",
            "[10/10] Completed: Gender-critical feminism\n",
            "Saved to Google Drive: /content/drive/MyDrive/feminist_theory_10.csv\n",
            "\n",
            "============================================================\n",
            "Successfully saved 10 articles to: feminist_theory_10.csv\n",
            "Total time: 0.2 minutes (0.93s per article)\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script type=\"module\">\n",
              "    import { set_or_remove_dark_class } from 'https://www.unpkg.com/dt_for_itables/dt_bundle.js';\n",
              "    set_or_remove_dark_class();\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Data Table\n",
            "============================================================\n",
            "How to use:\n",
            "SEARCH: Use the search box to filter across all columns\n",
            "SORT: Click column headers to sort (shift+click for multi-column)\n",
            "COLUMNS: Click 'Column visibility' button to show/hide columns\n",
            "PAGES: Use dropdown to change rows per page (10/25/50/100)\n",
            "EXPORT: Click 'CSV' or 'Excel' to download\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!--| quarto-html-table-processing: none -->\n",
              "<table id=\"itables_d392214b_d684_4bee_8da5_5916ad9b67b3\"><tbody><tr>\n",
              "    <td style=\"vertical-align:middle; text-align:left\">\n",
              "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
              "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
              "    <g style=\"fill:#d9d7fc\">\n",
              "        <path d=\"M100,400H500V357H100Z\" />\n",
              "        <path d=\"M100,300H400V257H100Z\" />\n",
              "        <path d=\"M0,200H400V157H0Z\" />\n",
              "        <path d=\"M100,100H500V57H100Z\" />\n",
              "        <path d=\"M100,350H500V307H100Z\" />\n",
              "        <path d=\"M100,250H400V207H100Z\" />\n",
              "        <path d=\"M0,150H400V107H0Z\" />\n",
              "        <path d=\"M100,50H500V7H100Z\" />\n",
              "    </g>\n",
              "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
              "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"0;0;400\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;300;0\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;400\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
              "            <g transform=\"translate(45 50) rotate(-45)\">\n",
              "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
              "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(450 152)\">\n",
              "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
              "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(50 352)\">\n",
              "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
              "                <polygon points=\"-35,10 0,45 35,10\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(75 250)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(425 250) rotate(180)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "        </g>\n",
              "    </g>\n",
              "</svg>\n",
              "</a>\n",
              "    Loading ITables v2.7.0 from the internet...\n",
              "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
              "    </tr></tbody></table>\n",
              "<link href=\"https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.css\" rel=\"stylesheet\">\n",
              "<script type=\"module\">\n",
              "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.js';\n",
              "\n",
              "    document.querySelectorAll(\"#itables_d392214b_d684_4bee_8da5_5916ad9b67b3:not(.dataTable)\").forEach(table => {\n",
              "        if (!(table instanceof HTMLTableElement))\n",
              "            return;\n",
              "\n",
              "        let dt_args = {\"scrollX\": true, \"scrollY\": \"600px\", \"paging\": true, \"lengthMenu\": [10, 25, 50, 100], \"pageLength\": 25, \"buttons\": [\"copy\", \"csv\", \"excel\", \"colvis\"], \"order\": [[1, \"desc\"]], \"columnDefs\": [{\"targets\": [14, 16, 21, 22, 24, 25, 26], \"render\": \"\\n                        function (data, type, row, meta) {\\n                            return type === 'sort' ? data[1] : data[0];\\n                        }\\n                    \"}, {\"className\": \"dt-left\", \"targets\": \"_all\"}], \"layout\": {\"topStart\": \"buttons\", \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"classes\": [\"display\", \"nowrap\", \"compact\"], \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"0\", \"caption-side\": \"bottom\"}, \"text_in_header_can_be_selected\": true, \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>Article</th>\\n      <th>Last 3 Months Views</th>\\n      <th>Word Count</th>\\n      <th>Talk Page Size</th>\\n      <th>Days Since Last Edit</th>\\n      <th>Edits Last Year</th>\\n      <th>Total Editors</th>\\n      <th>Images</th>\\n      <th>Citations</th>\\n      <th>Citations Needed</th>\\n      <th>Journal Sources</th>\\n      <th>Book Sources</th>\\n      <th>Web Sources</th>\\n      <th>News Sources</th>\\n      <th>Avg Source Age</th>\\n      <th>Recent Sources (5yr)</th>\\n      <th>Source Quality Score</th>\\n      <th>Hedging Words</th>\\n      <th>Peacock Words</th>\\n      <th>Weasel Words</th>\\n      <th>Value Judgments</th>\\n      <th>Neutrality Score</th>\\n      <th>Flesch-Kincaid Grade</th>\\n      <th>Reading Level</th>\\n      <th>Polarity</th>\\n      <th>Subjectivity</th>\\n      <th>VADER Compound</th>\\n      <th>Sentiment</th>\\n      <th>Categories</th>\\n      <th>Section Names</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"Feminist legal theory\\\", 2163, 2657, 6130, 257, 5, 122, 8, 23, 0, 19, 6, 2, 0, [\\\"20.4\\\", 4], 4, [\\\"76.3\\\", 4], 3, 0, 0, 0, [\\\"100.0\\\", 9], [\\\"14.4\\\", 2], \\\"Professional/Academic\\\", [\\\"0.137\\\", 10], [\\\"0.340\\\", 3], [\\\"0.994\\\", 9], \\\"Slight Bias\\\", 7, \\\"History, Main approaches, The liberal equality model, The sexual difference model, The dominance model, The anti-essentialist model, The postmodern model, Hedonic Jurisprudence, Influence on judicial decisions, Notable scholars, See also, Notes, References, Further reading, External links\\\"], [\\\"Feminist political theory\\\", 1909, 3668, 5676, 9, 52, 79, 4, 54, 0, 20, 12, 14, 1, [\\\"17.0\\\", 2], 16, [\\\"89.0\\\", 9], 1, 1, 2, 0, [\\\"89.1\\\", 5], [\\\"17.4\\\", 7], \\\"Professional/Academic\\\", [\\\"0.077\\\", 3], [\\\"0.329\\\", 1], [\\\"0.599\\\", 6], \\\"Neutral but Subjective\\\", 15, \\\"History, Early Works, Renaissance, Early Modern, Nineteenth Century, Women's Rights Movement (1800s - early 1900s), Women's Liberation Movement (1960s -1970s), Radical feminism, Liberal feminism, Marxist and socialist feminism, Ecological feminism, Postmodernist/Poststructuralist feminism, Topics of inquiry, Feminist epistemology, Gendered political institutions, Group identity/identity politics, Political leadership and gender, The Vulnerability Theory, The \\\\\\\"No-Problem\\\\\\\" Problem, Relational Theory of Autonomy, See also, Related journals, References, External links\\\"], [\\\"Feminist film theory\\\", 3819, 2542, 13344, 108, 7, 230, 5, 32, 0, 5, 2, 3, 0, [\\\"26.4\\\", 9], 0, [\\\"65.0\\\", 3], 1, 2, 2, 0, [\\\"80.3\\\", 1], [\\\"14.7\\\", 3], \\\"College Graduate\\\", [\\\"0.081\\\", 4], [\\\"0.398\\\", 8], [\\\"0.993\\\", 8], \\\"Neutral but Subjective\\\", 9, \\\"History, Key themes, The gaze and the female spectator, Realism and counter cinema, Additional theories, List of select feminist film theorists and critics, See also, References, Further reading\\\"], [\\\"Feminist literary criticism\\\", 7884, 2360, 8573, 11, 15, 251, 7, 19, 0, 0, 6, 8, 0, [\\\"23.6\\\", 5], 0, [\\\"41.4\\\", 2], 1, 1, 0, 1, [\\\"92.4\\\", 7], [\\\"16.6\\\", 6], \\\"Professional/Academic\\\", [\\\"0.103\\\", 8], [\\\"0.338\\\", 2], [\\\"-0.996\\\", 3], \\\"Slight Bias\\\", 11, \\\"Methods Employed, History and Critics, Modern applications, References, Further reading, External links\\\"], [\\\"Toward a Feminist Theory of the State\\\", 1350, 1149, 1211, 35, 1, 26, 4, 18, 1, 0, 0, 0, 0, [\\\"32.3\\\", 10], 0, [\\\"0.0\\\", 1], 3, 0, 0, 2, [\\\"86.1\\\", 3], [\\\"19.0\\\", 9], \\\"Professional/Academic\\\", [\\\"0.127\\\", 9], [\\\"0.409\\\", 10], [\\\"-0.980\\\", 4], \\\"Slight Bias\\\", 15, \\\"Summary, Reception, Academic reviews, Popular press, References\\\"], [\\\"Feminist theory\\\", 13336, 7541, 22137, 33, 14, 314, 14, 124, 0, 13, 23, 6, 2, [\\\"24.7\\\", 7], 6, [\\\"80.9\\\", 6], 12, 5, 2, 1, [\\\"88.3\\\", 4], [\\\"16.1\\\", 4], \\\"Professional/Academic\\\", [\\\"0.062\\\", 1], [\\\"0.363\\\", 5], [\\\"-0.976\\\", 5], \\\"Neutral but Subjective\\\", 16, \\\"History, Disciplines, Bodies, The standard and contemporary sex and gender system, Socially-biasing children sex and gender system, Epistemologies, Intersectionality, Language, Psychology, Psychoanalysis, Literary theory, Film theory, Art history, History, Geography, Philosophy, Sexology, Monosexual paradigm, Politics, Economics, Legal theory, Communication theory, Public relations, Design, Black feminist criminology, Feminist science and technology studies, Ecological feminism or ecofeminism, Girls studies and boys studies, See also, References, Further reading, External links\\\"], [\\\"Feminist sociology\\\", 1101, 2802, 6808, 43, 2, 133, 11, 35, 0, 20, 35, 6, 1, [\\\"23.7\\\", 6], 0, [\\\"84.4\\\", 7], 2, 3, 1, 0, [\\\"83.9\\\", 2], [\\\"14.7\\\", 3], \\\"College Graduate\\\", [\\\"0.083\\\", 5], [\\\"0.404\\\", 9], [\\\"-0.999\\\", 2], \\\"Neutral but Subjective\\\", 11, \\\"History, Feminism and race, Feminism and stratification, Feminism and gender, Feminism and queer theory, Feminist critiques of multiculturalism, Types of feminism, Criticism of feminist sociology, Anti-feminism, References, Further reading\\\"], [\\\"Third-wave feminism\\\", 37900, 4080, 1672, 29, 20, 277, 14, 92, 1, 17, 41, 27, 9, [\\\"18.2\\\", 3], 7, [\\\"85.9\\\", 8], 8, 1, 0, 1, [\\\"95.6\\\", 8], [\\\"13.6\\\", 1], \\\"College Graduate\\\", [\\\"0.088\\\", 6], [\\\"0.376\\\", 6], [\\\"-0.999\\\", 2], \\\"Neutral but Subjective\\\", 13, \\\"Background, Global Influence, Early years, Anita Hill, Riot grrrl, Purpose, Relationship with second wave, Issues, Violence against women, Reproductive rights, Reclaiming derogatory terms, Sexual liberation, Other issues, Criticism, Lack of cohesion, Objection to \\\\\\\"wave construct\\\\\\\", Relationship with women of color, \\\\\\\"Girly\\\\\\\" feminism, Timeline, 1990s, 2000s, Notes, References, Bibliography, Further reading, Suggested listening, External links\\\"], [\\\"Feminism\\\", 120152, 10877, 14353, 53, 104, 201, 39, 348, 3, 56, 183, 62, 24, [\\\"24.9\\\", 8], 23, [\\\"76.8\\\", 5], 10, 6, 1, 1, [\\\"92.4\\\", 7], [\\\"16.2\\\", 5], \\\"Professional/Academic\\\", [\\\"0.092\\\", 7], [\\\"0.351\\\", 4], [\\\"0.960\\\", 7], \\\"Neutral but Subjective\\\", 30, \\\"History, Terminology, Waves, 19th and early 20th centuries, Mid-20th century, Late 20th and early 21st centuries, Third-wave feminism, Standpoint theory, Fourth-wave feminism, Decolonial feminism, Postfeminism, Theory, Movements and ideologies, Liberal feminism, Radical feminism, Materialist ideologies, Other modern feminisms, Ecofeminism, Black and postcolonial ideologies, Social constructionist ideologies, Transgender people, Cultural movements, Demographics, Sexuality, Sex industry, Affirming female sexual autonomy, Science, Biology and gender, Feminist psychology, Culture, Design, Businesses, Visual arts, Literature, Music, Cinema, Politics, Socialism, Fascism, Civil rights movement and anti-racism, Neoliberalism, Societal impact, Civil rights, Jurisprudence, Language, Theology, Patriarchy, Men and masculinity, Reactions, Pro-feminism, Criticism of feminism, Anti-feminism, Secular humanism, See also, Explanatory notes, References, External links, Articles, Multimedia and documents, Books\\\"], [\\\"Gender-critical feminism\\\", 23750, 6855, 43075, 2, 341, 109, 16, 181, 0, 65, 19, 43, 37, [\\\"5.6\\\", 1], 162, [\\\"90.6\\\", 10], 8, 3, 2, 1, [\\\"90.1\\\", 6], [\\\"18.5\\\", 8], \\\"Professional/Academic\\\", [\\\"0.072\\\", 2], [\\\"0.396\\\", 7], [\\\"-1.000\\\", 1], \\\"Neutral but Subjective\\\", 27, \\\"Terminology, Trans-exclusionary radical feminism, Gender-critical feminism, Views, Sex and gender, \\\\\\\"Sex-based rights\\\\\\\", Inclusive language, Socialisation and gender nonconformity, Gender transition, Transgender youth, Intersex conditions, Sexual orientation, Conversion therapy, History, Early history (before 2000), By country, Europe, France, Germany, Asia, China, Japan, Turkey, Analysis, Scholarly analysis, Relationship with feminism, Relationship with the anti-gender movement, Political alliances with conservatives and the far right, Misinformation and disinformation, Controversies, Academic freedom, Conflicts with other feminist and pro-equality groups, Social media, Symbolism and iconography, See also, References, Further reading, External links\\\"]]\", \"keys_to_be_evaluated\": [[\"columnDefs\", 0, \"render\"]]};\n",
              "        new ITable(table, dt_args);\n",
              "    });\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Summary Statistics\n",
            "============================================================\n",
            "       Last 3 Months Views  Word Count  Talk Page Size  Citations  Days Since Last Edit  Source Quality Score  Neutrality Score  Flesch-Kincaid Grade  Polarity  Subjectivity\n",
            "count                 10.0        10.0            10.0       10.0                  10.0                  10.0              10.0                  10.0      10.0          10.0\n",
            "mean               21336.4      4453.1         12297.9       92.6                  58.0                  69.0              89.8                  16.1       0.1           0.4\n",
            "std                36743.1      3022.7         12521.5      104.5                  76.1                  28.3               5.7                   1.8       0.0           0.0\n",
            "min                 1101.0      1149.0          1211.0       18.0                   2.0                   0.0              80.3                  13.6       0.1           0.3\n",
            "25%                 1972.5      2570.8          5789.5       25.2                  15.5                  67.8              86.6                  14.7       0.1           0.3\n",
            "50%                 5851.5      3235.0          7690.5       44.5                  34.0                  78.8              89.6                  16.2       0.1           0.4\n",
            "75%                21146.5      6161.2         14100.8      116.0                  50.5                  85.5              92.4                  17.2       0.1           0.4\n",
            "max               120152.0     10877.0         43075.0      348.0                 257.0                  90.6             100.0                  19.0       0.1           0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the articles you have found using easy to digest ratings:"
      ],
      "metadata": {
        "id": "pX6Z8mLWpxcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2d9Y2nsj8gAS",
        "outputId": "07d06cd0-f89b-49bc-9746-ee563ff9d9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "COMPOSITE SCORES CALCULATED\n",
            "============================================================\n",
            "\n",
            "Score Definitions:\n",
            "- Collaboration: Average of (Total Editors + Talk Page Size)\n",
            "- Aliveness: Average of (Days Since Edit [inverted] + Edits Last Year)\n",
            "- Popularity: Page Views\n",
            "- Quality: Weighted average of content metrics, sources, and neutrality\n",
            "- Scholarly Source: Quality and recency of academic sources\n",
            "- NPOV Score: Neutral Point of View compliance\n",
            "- Accessibility: Reading level\n",
            "\n",
            "All scores are on a 0-100 percentile scale.\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 Article  Collaboration Score  Aliveness Score  Popularity Score  Quality Score  Scholarly Source Score  NPOV Score  Accessibility Score                                                       Wikipedia Link                                                                                                                                                                                                                                                                            IIT Library Link\n",
              "0                  Feminist legal theory                   40               15                40             46                      48          85                   80                  https://en.wikipedia.org/wiki/Feminist_legal_theory                          https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20legal%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "1              Feminist political theory                   25               80                30             62                      76          58                   20              https://en.wikipedia.org/wiki/Feminist_political_theory                      https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20political%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "2                   Feminist film theory                   70               25                50             29                      26          18                   65                   https://en.wikipedia.org/wiki/Feminist_film_theory                           https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20film%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "3            Feminist literary criticism                   70               65                60             37                      25          74                   30            https://en.wikipedia.org/wiki/Feminist_literary_criticism                    https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20literary%20criticism,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "4  Toward a Feminist Theory of the State                   10               25                20             31                      12          36                    0  https://en.wikipedia.org/wiki/Toward_a_Feminist_Theory_of_the_State  https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Toward%20a%20Feminist%20Theory%20of%20the%20State,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "5                        Feminist theory                   95               50                70             62                      53          35                   50                        https://en.wikipedia.org/wiki/Feminist_theory                                  https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "6                     Feminist sociology                   50               25                10             42                      66          22                   65                     https://en.wikipedia.org/wiki/Feminist_sociology                               https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20sociology,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "7                    Third-wave feminism                   55               65                90             71                      71          68                   90                    https://en.wikipedia.org/wiki/Third-wave_feminism                              https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Third-wave%20feminism,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "8                               Feminism                   70               55               100             75                      73          55                   40                               https://en.wikipedia.org/wiki/Feminism                                           https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminism,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\n",
              "9               Gender-critical feminism                   65               95                80             80                      91          39                   10               https://en.wikipedia.org/wiki/Gender-critical_feminism                         https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Gender-critical%20feminism,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f81f1c62-5642-41fc-bebe-f6182c195a6a\" class=\"colab-df-container\">\n",
              "    <!--| quarto-html-table-processing: none -->\n",
              "<table id=\"itables_d8e04618_6d66_4474_a98c_78ff409947ec\"><tbody><tr>\n",
              "    <td style=\"vertical-align:middle; text-align:left\">\n",
              "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
              "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
              "    <g style=\"fill:#d9d7fc\">\n",
              "        <path d=\"M100,400H500V357H100Z\" />\n",
              "        <path d=\"M100,300H400V257H100Z\" />\n",
              "        <path d=\"M0,200H400V157H0Z\" />\n",
              "        <path d=\"M100,100H500V57H100Z\" />\n",
              "        <path d=\"M100,350H500V307H100Z\" />\n",
              "        <path d=\"M100,250H400V207H100Z\" />\n",
              "        <path d=\"M0,150H400V107H0Z\" />\n",
              "        <path d=\"M100,50H500V7H100Z\" />\n",
              "    </g>\n",
              "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
              "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"0;0;400\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;300;0\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;400\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
              "            <g transform=\"translate(45 50) rotate(-45)\">\n",
              "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
              "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(450 152)\">\n",
              "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
              "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(50 352)\">\n",
              "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
              "                <polygon points=\"-35,10 0,45 35,10\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(75 250)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(425 250) rotate(180)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "        </g>\n",
              "    </g>\n",
              "</svg>\n",
              "</a>\n",
              "    Loading ITables v2.7.0 from the internet...\n",
              "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
              "    </tr></tbody></table>\n",
              "<link href=\"https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.css\" rel=\"stylesheet\">\n",
              "<script type=\"module\">\n",
              "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.js';\n",
              "\n",
              "    document.querySelectorAll(\"#itables_d8e04618_6d66_4474_a98c_78ff409947ec:not(.dataTable)\").forEach(table => {\n",
              "        if (!(table instanceof HTMLTableElement))\n",
              "            return;\n",
              "\n",
              "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"auto\", \"caption-side\": \"bottom\"}, \"text_in_header_can_be_selected\": true, \"order\": [], \"classes\": [\"display\", \"nowrap\", \"compact\"], \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>Article</th>\\n      <th>Collaboration Score</th>\\n      <th>Aliveness Score</th>\\n      <th>Popularity Score</th>\\n      <th>Quality Score</th>\\n      <th>Scholarly Source Score</th>\\n      <th>NPOV Score</th>\\n      <th>Accessibility Score</th>\\n      <th>Wikipedia Link</th>\\n      <th>IIT Library Link</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"Feminist legal theory\\\", 40, 15, 40, 46, 48, 85, 80, \\\"https://en.wikipedia.org/wiki/Feminist_legal_theory\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20legal%20theory,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminist political theory\\\", 25, 80, 30, 62, 76, 58, 20, \\\"https://en.wikipedia.org/wiki/Feminist_political_theory\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20political%20theory,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminist film theory\\\", 70, 25, 50, 29, 26, 18, 65, \\\"https://en.wikipedia.org/wiki/Feminist_film_theory\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20film%20theory,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminist literary criticism\\\", 70, 65, 60, 37, 25, 74, 30, \\\"https://en.wikipedia.org/wiki/Feminist_literary_criticism\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20literary%20criticism,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Toward a Feminist Theory of the State\\\", 10, 25, 20, 31, 12, 36, 0, \\\"https://en.wikipedia.org/wiki/Toward_a_Feminist_Theory_of_the_State\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Toward%20a%20Feminist%20Theory%20of%20the%20State,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminist theory\\\", 95, 50, 70, 62, 53, 35, 50, \\\"https://en.wikipedia.org/wiki/Feminist_theory\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20theory,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminist sociology\\\", 50, 25, 10, 42, 66, 22, 65, \\\"https://en.wikipedia.org/wiki/Feminist_sociology\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20sociology,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Third-wave feminism\\\", 55, 65, 90, 71, 71, 68, 90, \\\"https://en.wikipedia.org/wiki/Third-wave_feminism\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Third-wave%20feminism,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Feminism\\\", 70, 55, 100, 75, 73, 55, 40, \\\"https://en.wikipedia.org/wiki/Feminism\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminism,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"], [\\\"Gender-critical feminism\\\", 65, 95, 80, 80, 91, 39, 10, \\\"https://en.wikipedia.org/wiki/Gender-critical_feminism\\\", \\\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Gender-critical%20feminism,AND&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;sortby=rank&amp;vid=01CARLI_IIT:CARLI_IIT&amp;mfacet=tlevel,include,peer_reviewed,1&amp;lang=en&amp;mode=advanced&amp;offset=0\\\"]]\"};\n",
              "        new ITable(table, dt_args);\n",
              "    });\n",
              "</script>\n",
              "\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f81f1c62-5642-41fc-bebe-f6182c195a6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f81f1c62-5642-41fc-bebe-f6182c195a6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f81f1c62-5642-41fc-bebe-f6182c195a6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Google Drive not mounted\\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Feminism\",\n          \"Feminist political theory\",\n          \"Feminist theory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Collaboration Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 10,\n        \"max\": 95,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          25,\n          50,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Aliveness Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 15,\n        \"max\": 95,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15,\n          80,\n          55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Popularity Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 10,\n        \"max\": 100,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          100,\n          30,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quality Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 29,\n        \"max\": 80,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          75,\n          62,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scholarly Source Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 12,\n        \"max\": 91,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          73,\n          76,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NPOV Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 18,\n        \"max\": 85,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          55,\n          58,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accessibility Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 90,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          40,\n          20,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wikipedia Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://en.wikipedia.org/wiki/Feminism\",\n          \"https://en.wikipedia.org/wiki/Feminist_political_theory\",\n          \"https://en.wikipedia.org/wiki/Feminist_theory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IIT Library Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminism,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\",\n          \"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20political%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\",\n          \"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,Feminist%20theory,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Composite Score Statistics:\n",
            "============================================================\n",
            "                        count  mean   std   min   25%   50%   75%    max\n",
            "Collaboration Score      10.0  55.0  24.8  10.0  42.5  60.0  70.0   95.0\n",
            "Aliveness Score          10.0  50.0  26.9  15.0  25.0  52.5  65.0   95.0\n",
            "Popularity Score         10.0  55.0  30.3  10.0  32.5  55.0  77.5  100.0\n",
            "Quality Score            10.0  53.5  18.8  29.0  38.2  54.0  68.8   80.0\n",
            "Scholarly Source Score   10.0  54.1  26.0  12.0  31.5  59.5  72.5   91.0\n",
            "NPOV Score               10.0  49.0  22.5  18.0  35.2  47.0  65.5   85.0\n",
            "Accessibility Score      10.0  45.0  30.2   0.0  22.5  45.0  65.0   90.0\n",
            "\n",
            "============================================================\n",
            "TOP 5 ARTICLES BY EACH SCORE:\n",
            "============================================================\n",
            "\n",
            "Most Collaborative:\n",
            "                       Article  Collaboration Score  Total Editors  Talk Page Size\n",
            "5              Feminist theory                   95            314           22137\n",
            "2         Feminist film theory                   70            230           13344\n",
            "3  Feminist literary criticism                   70            251            8573\n",
            "8                     Feminism                   70            201           14353\n",
            "9     Gender-critical feminism                   65            109           43075\n",
            "\n",
            "Most Alive:\n",
            "                       Article  Aliveness Score  Days Since Last Edit  Edits Last Year\n",
            "9     Gender-critical feminism               95                     2              341\n",
            "1    Feminist political theory               80                     9               52\n",
            "3  Feminist literary criticism               65                    11               15\n",
            "7          Third-wave feminism               65                    29               20\n",
            "8                     Feminism               55                    53              104\n",
            "\n",
            "Most Popular:\n",
            "                       Article  Popularity Score  Last 3 Months Views\n",
            "8                     Feminism               100               120152\n",
            "7          Third-wave feminism                90                37900\n",
            "9     Gender-critical feminism                80                23750\n",
            "5              Feminist theory                70                13336\n",
            "3  Feminist literary criticism                60                 7884\n",
            "\n",
            "Highest Quality:\n",
            "                     Article  Quality Score  Citations  Source Quality Score  Neutrality Score\n",
            "9   Gender-critical feminism             80        181                  90.6              90.1\n",
            "8                   Feminism             75        348                  76.8              92.4\n",
            "7        Third-wave feminism             71         92                  85.9              95.6\n",
            "1  Feminist political theory             62         54                  89.0              89.1\n",
            "5            Feminist theory             62        124                  80.9              88.3\n",
            "\n",
            "Best Scholarly Sources:\n",
            "                     Article  Scholarly Source Score  Journal Sources  Book Sources\n",
            "9   Gender-critical feminism                      91               65            19\n",
            "1  Feminist political theory                      76               20            12\n",
            "8                   Feminism                      73               56           183\n",
            "7        Third-wave feminism                      71               17            41\n",
            "6         Feminist sociology                      66               20            35\n",
            "\n",
            "Most Neutral (NPOV):\n",
            "                       Article  NPOV Score  Neutrality Score  Objectivity Percentile\n",
            "0        Feminist legal theory          85             100.0                    70.0\n",
            "3  Feminist literary criticism          74              92.4                    80.0\n",
            "7          Third-wave feminism          68              95.6                    40.0\n",
            "1    Feminist political theory          58              89.1                    90.0\n",
            "8                     Feminism          55              92.4                    60.0\n",
            "\n",
            "Most Accessible:\n",
            "                 Article  Accessibility Score          Reading Level  Flesch-Kincaid Grade\n",
            "7    Third-wave feminism                   90       College Graduate                  13.6\n",
            "0  Feminist legal theory                   80  Professional/Academic                  14.4\n",
            "2   Feminist film theory                   65       College Graduate                  14.7\n",
            "6     Feminist sociology                   65       College Graduate                  14.7\n",
            "5        Feminist theory                   50  Professional/Academic                  16.1\n",
            "\n",
            "Saved locally to: feminist_theory_10_WITH_SCORES.csv\n",
            "Saved to Google Drive: /content/drive/MyDrive/feminist_theory_10_WITH_SCORES.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Load the CSV file\n",
        "path = \"/content/feminist_theory_10.csv\" #@param {type:\"string\"}\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# Function to calculate percentile rank (0-100 scale)\n",
        "def percentile_rank(series):\n",
        "    \"\"\"Convert values to percentile ranks (0-100)\"\"\"\n",
        "    return series.rank(pct=True) * 100\n",
        "\n",
        "# ============================================\n",
        "# CREATE LINKS FIRST (before percentile calculations)\n",
        "# ============================================\n",
        "\n",
        "# Wikipedia link\n",
        "df['Wikipedia Link'] = df['Article'].apply(\n",
        "    lambda x: f\"https://en.wikipedia.org/wiki/{x.replace(' ', '_')}\"\n",
        ")\n",
        "\n",
        "# IIT Library search link\n",
        "df['IIT Library Link'] = df[\"Article\"].str.replace(' ', '%20').apply(\n",
        "    lambda x: f\"https://i-share-iit.primo.exlibrisgroup.com/discovery/search?query=any,contains,{x},AND&tab=Everything&search_scope=MyInst_and_CI&sortby=rank&vid=01CARLI_IIT:CARLI_IIT&mfacet=tlevel,include,peer_reviewed,1&lang=en&mode=advanced&offset=0\"\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# CALCULATE PERCENTILES FOR ALL METRICS\n",
        "# ============================================\n",
        "\n",
        "# Activity/Collaboration metrics\n",
        "df['Days Since Edit Percentile'] = 100 - percentile_rank(df['Days Since Last Edit'])\n",
        "df['Edits Last Year Percentile'] = percentile_rank(df['Edits Last Year'])\n",
        "df['Total Editors Percentile'] = percentile_rank(df['Total Editors'])\n",
        "df['Talk Page Percentile'] = percentile_rank(df['Talk Page Size'])\n",
        "\n",
        "# Popularity\n",
        "df['Views Percentile'] = percentile_rank(df['Last 3 Months Views'])\n",
        "\n",
        "# Content quality\n",
        "df['Word Count Percentile'] = percentile_rank(df['Word Count'])\n",
        "df['Images Percentile'] = percentile_rank(df['Images'])\n",
        "df['Categories Percentile'] = percentile_rank(df['Categories'])\n",
        "df['Citations Percentile'] = percentile_rank(df['Citations'])\n",
        "df['Citation Needed Percentile'] = 100 - percentile_rank(df['Citations Needed'])\n",
        "df['Citation/Word Ratio Percentile'] = percentile_rank(df['Citations'] / df['Word Count'].replace(0, 1))\n",
        "\n",
        "# Source quality metrics\n",
        "df['Source Quality Percentile'] = percentile_rank(df['Source Quality Score'])\n",
        "df['Journal Sources Percentile'] = percentile_rank(df['Journal Sources'])\n",
        "df['Book Sources Percentile'] = percentile_rank(df['Book Sources'])\n",
        "df['Recent Sources Percentile'] = percentile_rank(df['Recent Sources (5yr)'])\n",
        "df['Source Age Percentile'] = 100 - percentile_rank(df['Avg Source Age'])\n",
        "\n",
        "# Neutrality and bias metrics\n",
        "df['Neutrality Percentile'] = percentile_rank(df['Neutrality Score'])\n",
        "df['Peacock Words Percentile'] = 100 - percentile_rank(df['Peacock Words'])\n",
        "df['Weasel Words Percentile'] = 100 - percentile_rank(df['Weasel Words'])\n",
        "df['Value Judgments Percentile'] = 100 - percentile_rank(df['Value Judgments'])\n",
        "\n",
        "# Readability metrics\n",
        "df['Reading Level Percentile'] = 100 - percentile_rank(df['Flesch-Kincaid Grade'])\n",
        "\n",
        "# Sentiment metrics\n",
        "df['Polarity Neutrality Percentile'] = 100 - percentile_rank(df['Polarity'].abs())\n",
        "df['Objectivity Percentile'] = 100 - percentile_rank(df['Subjectivity'])\n",
        "\n",
        "# ============================================\n",
        "# CREATE COMPOSITE SCORES\n",
        "# ============================================\n",
        "\n",
        "# Collaboration Score\n",
        "df['Collaboration Score'] = (\n",
        "    (df['Total Editors Percentile'] + df['Talk Page Percentile']) / 2\n",
        ").round().astype(int)\n",
        "\n",
        "# Aliveness Score\n",
        "df['Aliveness Score'] = (\n",
        "    (df['Days Since Edit Percentile'] + df['Edits Last Year Percentile']) / 2\n",
        ").round().astype(int)\n",
        "\n",
        "# Popularity Score\n",
        "df['Popularity Score'] = df['Views Percentile'].round().astype(int)\n",
        "\n",
        "# Quality Score\n",
        "df['Quality Score'] = (\n",
        "    df['Citation/Word Ratio Percentile'] * 0.25 +\n",
        "    df['Images Percentile'] * 0.10 +\n",
        "    df['Categories Percentile'] * 0.10 +\n",
        "    df['Citation Needed Percentile'] * 0.05 +\n",
        "    df['Source Quality Percentile'] * 0.25 +\n",
        "    df['Neutrality Percentile'] * 0.15 +\n",
        "    df['Objectivity Percentile'] * 0.10\n",
        ").round().astype(int)\n",
        "\n",
        "# Scholarly Source Score\n",
        "df['Scholarly Source Score'] = (\n",
        "    df['Source Quality Percentile'] * 0.30 +\n",
        "    df['Journal Sources Percentile'] * 0.30 +\n",
        "    df['Book Sources Percentile'] * 0.20 +\n",
        "    df['Recent Sources Percentile'] * 0.10 +\n",
        "    df['Source Age Percentile'] * 0.10\n",
        ").round().astype(int)\n",
        "\n",
        "# NPOV Score\n",
        "df['NPOV Score'] = (\n",
        "    df['Neutrality Percentile'] * 0.40 +\n",
        "    df['Objectivity Percentile'] * 0.30 +\n",
        "    df['Peacock Words Percentile'] * 0.15 +\n",
        "    df['Weasel Words Percentile'] * 0.15\n",
        ").round().astype(int)\n",
        "\n",
        "# Accessibility Score\n",
        "df['Accessibility Score'] = df['Reading Level Percentile'].round().astype(int)\n",
        "\n",
        "# ============================================\n",
        "# DISPLAY RESULTS\n",
        "# ============================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPOSITE SCORES CALCULATED\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nScore Definitions:\")\n",
        "print(\"- Collaboration: Average of (Total Editors + Talk Page Size)\")\n",
        "print(\"- Aliveness: Average of (Days Since Edit [inverted] + Edits Last Year)\")\n",
        "print(\"- Popularity: Page Views\")\n",
        "print(\"- Quality: Weighted average of content metrics, sources, and neutrality\")\n",
        "print(\"- Scholarly Source: Quality and recency of academic sources\")\n",
        "print(\"- NPOV Score: Neutral Point of View compliance\")\n",
        "print(\"- Accessibility: Reading level\")\n",
        "print(\"\\nAll scores are on a 0-100 percentile scale.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display core composite scores with links\n",
        "display(df[['Article', 'Collaboration Score',\n",
        "            'Aliveness Score', 'Popularity Score', 'Quality Score', 'Scholarly Source Score',\n",
        "            'NPOV Score', 'Accessibility Score', 'Wikipedia Link', 'IIT Library Link']])\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Composite Score Statistics:\")\n",
        "print(\"=\"*60)\n",
        "score_cols = ['Collaboration Score', 'Aliveness Score', 'Popularity Score', 'Quality Score',\n",
        "              'Scholarly Source Score', 'NPOV Score', 'Accessibility Score']\n",
        "print(df[score_cols].describe().round(1).T)\n",
        "\n",
        "# ============================================\n",
        "# TOP ARTICLES BY EACH SCORE\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP 5 ARTICLES BY EACH SCORE:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nMost Collaborative:\")\n",
        "print(df.nlargest(5, 'Collaboration Score')[['Article', 'Collaboration Score', 'Total Editors', 'Talk Page Size']])\n",
        "\n",
        "print(\"\\nMost Alive:\")\n",
        "print(df.nlargest(5, 'Aliveness Score')[['Article', 'Aliveness Score', 'Days Since Last Edit', 'Edits Last Year']])\n",
        "\n",
        "print(\"\\nMost Popular:\")\n",
        "print(df.nlargest(5, 'Popularity Score')[['Article', 'Popularity Score', 'Last 3 Months Views']])\n",
        "\n",
        "print(\"\\nHighest Quality:\")\n",
        "print(df.nlargest(5, 'Quality Score')[['Article', 'Quality Score', 'Citations', 'Source Quality Score', 'Neutrality Score']])\n",
        "\n",
        "print(\"\\nBest Scholarly Sources:\")\n",
        "print(df.nlargest(5, 'Scholarly Source Score')[['Article', 'Scholarly Source Score', 'Journal Sources', 'Book Sources']])\n",
        "\n",
        "print(\"\\nMost Neutral (NPOV):\")\n",
        "print(df.nlargest(5, 'NPOV Score')[['Article', 'NPOV Score', 'Neutrality Score', 'Objectivity Percentile']])\n",
        "\n",
        "print(\"\\nMost Accessible:\")\n",
        "print(df.nlargest(5, 'Accessibility Score')[['Article', 'Accessibility Score', 'Reading Level', 'Flesch-Kincaid Grade']])\n",
        "\n",
        "# ============================================\n",
        "# SAVE RESULTS\n",
        "# ============================================\n",
        "\n",
        "# Drop percentile columns (keep only final scores)\n",
        "percentile_cols = [col for col in df.columns if 'Percentile' in col]\n",
        "df_final = df.drop(columns=percentile_cols)\n",
        "\n",
        "# Save to local\n",
        "filename_with_scores = path.split('/')[-1].replace('.csv', '_WITH_SCORES.csv')\n",
        "df_final.to_csv(filename_with_scores, index=False)\n",
        "print(f\"\\nSaved locally to: {filename_with_scores}\")\n",
        "\n",
        "# Save to Google Drive\n",
        "try:\n",
        "    drive_filename = \"/content/drive/MyDrive/\" + filename_with_scores\n",
        "    df_final.to_csv(drive_filename, index=False)\n",
        "    print(f\"Saved to Google Drive: {drive_filename}\")\n",
        "except:\n",
        "    print(\"Google Drive not mounted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can combine two CSVs by pasting their paths here:"
      ],
      "metadata": {
        "id": "g2O7RaOko4-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yd5pD4PkxMYT"
      },
      "outputs": [],
      "source": [
        "#combine dfs\n",
        "path1 = \"/content/wikipedia_psychology_C-Class_FINAL_ajose3@hawk.illinoistech.edu.csv\" #@param {type:\"string\"}\n",
        "path2 = \"/content/wikipedia_psychology_C-Class_FINAL_ajose3@hawk.illinoistech.edu.csv\" #@param {type:\"string\"}\n",
        "# Read CSVs into DataFrame\n",
        "First_Sheet = pd.read_csv(path1)\n",
        "Second_Sheet = pd.read_csv(path2)\n",
        "dfs = [First_Sheet,Second_Sheet]\n",
        "combined_df = pd.concat(dfs, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See any given CSVs data:"
      ],
      "metadata": {
        "id": "l3H9Rt_dpLiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "9KZaqPX9jmQI",
        "outputId": "eaca242c-db54-4476-c63f-50a0ba07f883"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!--| quarto-html-table-processing: none -->\n",
              "<table id=\"itables_15d2104c_2aa4_401b_8892_35b47ba26b52\"><tbody><tr>\n",
              "    <td style=\"vertical-align:middle; text-align:left\">\n",
              "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
              "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
              "    <g style=\"fill:#d9d7fc\">\n",
              "        <path d=\"M100,400H500V357H100Z\" />\n",
              "        <path d=\"M100,300H400V257H100Z\" />\n",
              "        <path d=\"M0,200H400V157H0Z\" />\n",
              "        <path d=\"M100,100H500V57H100Z\" />\n",
              "        <path d=\"M100,350H500V307H100Z\" />\n",
              "        <path d=\"M100,250H400V207H100Z\" />\n",
              "        <path d=\"M0,150H400V107H0Z\" />\n",
              "        <path d=\"M100,50H500V7H100Z\" />\n",
              "    </g>\n",
              "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
              "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"0;0;400\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;300;0\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;400\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
              "            <g transform=\"translate(45 50) rotate(-45)\">\n",
              "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
              "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(450 152)\">\n",
              "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
              "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(50 352)\">\n",
              "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
              "                <polygon points=\"-35,10 0,45 35,10\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(75 250)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(425 250) rotate(180)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "        </g>\n",
              "    </g>\n",
              "</svg>\n",
              "</a>\n",
              "    Loading ITables v2.7.0 from the internet...\n",
              "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
              "    </tr></tbody></table>\n",
              "<link href=\"https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.css\" rel=\"stylesheet\">\n",
              "<script type=\"module\">\n",
              "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.5.0/dt_bundle.js';\n",
              "\n",
              "    document.querySelectorAll(\"#itables_15d2104c_2aa4_401b_8892_35b47ba26b52:not(.dataTable)\").forEach(table => {\n",
              "        if (!(table instanceof HTMLTableElement))\n",
              "            return;\n",
              "\n",
              "        let dt_args = {\"scrollX\": true, \"scrollY\": \"600px\", \"paging\": true, \"lengthMenu\": [10, 25, 50, 100], \"pageLength\": 25, \"buttons\": [\"copy\", \"csv\", \"excel\", \"colvis\"], \"order\": [[1, \"desc\"]], \"columnDefs\": [{\"targets\": [14, 16, 21, 22, 24, 25, 26], \"render\": \"\\n                        function (data, type, row, meta) {\\n                            return type === 'sort' ? data[1] : data[0];\\n                        }\\n                    \"}, {\"className\": \"dt-left\", \"targets\": \"_all\"}], \"layout\": {\"topStart\": \"buttons\", \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"classes\": [\"display\", \"nowrap\", \"compact\"], \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"0\", \"caption-side\": \"bottom\"}, \"text_in_header_can_be_selected\": true, \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>Article</th>\\n      <th>Last 3 Months Views</th>\\n      <th>Word Count</th>\\n      <th>Talk Page Size</th>\\n      <th>Days Since Last Edit</th>\\n      <th>Edits Last Year</th>\\n      <th>Total Editors</th>\\n      <th>Images</th>\\n      <th>Citations</th>\\n      <th>Citations Needed</th>\\n      <th>Journal Sources</th>\\n      <th>Book Sources</th>\\n      <th>Web Sources</th>\\n      <th>News Sources</th>\\n      <th>Avg Source Age</th>\\n      <th>Recent Sources (5yr)</th>\\n      <th>Source Quality Score</th>\\n      <th>Hedging Words</th>\\n      <th>Peacock Words</th>\\n      <th>Weasel Words</th>\\n      <th>Value Judgments</th>\\n      <th>Neutrality Score</th>\\n      <th>Flesch-Kincaid Grade</th>\\n      <th>Reading Level</th>\\n      <th>Polarity</th>\\n      <th>Subjectivity</th>\\n      <th>VADER Compound</th>\\n      <th>Sentiment</th>\\n      <th>Categories</th>\\n      <th>Section Names</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"Feminist legal theory\\\", 2163, 2657, 6130, 257, 5, 122, 8, 23, 0, 19, 6, 2, 0, [\\\"20.4\\\", 4], 4, [\\\"76.3\\\", 4], 3, 0, 0, 0, [\\\"100.0\\\", 9], [\\\"14.4\\\", 2], \\\"Professional/Academic\\\", [\\\"0.137\\\", 10], [\\\"0.340\\\", 3], [\\\"0.994\\\", 9], \\\"Slight Bias\\\", 7, \\\"History, Main approaches, The liberal equality model, The sexual difference model, The dominance model, The anti-essentialist model, The postmodern model, Hedonic Jurisprudence, Influence on judicial decisions, Notable scholars, See also, Notes, References, Further reading, External links\\\"], [\\\"Feminist political theory\\\", 1909, 3668, 5676, 9, 52, 79, 4, 54, 0, 20, 12, 14, 1, [\\\"17.0\\\", 2], 16, [\\\"89.0\\\", 9], 1, 1, 2, 0, [\\\"89.1\\\", 5], [\\\"17.4\\\", 7], \\\"Professional/Academic\\\", [\\\"0.077\\\", 3], [\\\"0.329\\\", 1], [\\\"0.599\\\", 6], \\\"Neutral but Subjective\\\", 15, \\\"History, Early Works, Renaissance, Early Modern, Nineteenth Century, Women's Rights Movement (1800s - early 1900s), Women's Liberation Movement (1960s -1970s), Radical feminism, Liberal feminism, Marxist and socialist feminism, Ecological feminism, Postmodernist/Poststructuralist feminism, Topics of inquiry, Feminist epistemology, Gendered political institutions, Group identity/identity politics, Political leadership and gender, The Vulnerability Theory, The \\\\\\\"No-Problem\\\\\\\" Problem, Relational Theory of Autonomy, See also, Related journals, References, External links\\\"], [\\\"Feminist film theory\\\", 3819, 2542, 13344, 108, 7, 230, 5, 32, 0, 5, 2, 3, 0, [\\\"26.4\\\", 9], 0, [\\\"65.0\\\", 3], 1, 2, 2, 0, [\\\"80.3\\\", 1], [\\\"14.7\\\", 3], \\\"College Graduate\\\", [\\\"0.081\\\", 4], [\\\"0.398\\\", 8], [\\\"0.993\\\", 8], \\\"Neutral but Subjective\\\", 9, \\\"History, Key themes, The gaze and the female spectator, Realism and counter cinema, Additional theories, List of select feminist film theorists and critics, See also, References, Further reading\\\"], [\\\"Feminist theory\\\", 13336, 7541, 22137, 33, 14, 314, 14, 124, 0, 13, 23, 6, 2, [\\\"24.7\\\", 7], 6, [\\\"80.9\\\", 6], 12, 5, 2, 1, [\\\"88.3\\\", 4], [\\\"16.1\\\", 4], \\\"Professional/Academic\\\", [\\\"0.062\\\", 1], [\\\"0.363\\\", 5], [\\\"-0.976\\\", 5], \\\"Neutral but Subjective\\\", 16, \\\"History, Disciplines, Bodies, The standard and contemporary sex and gender system, Socially-biasing children sex and gender system, Epistemologies, Intersectionality, Language, Psychology, Psychoanalysis, Literary theory, Film theory, Art history, History, Geography, Philosophy, Sexology, Monosexual paradigm, Politics, Economics, Legal theory, Communication theory, Public relations, Design, Black feminist criminology, Feminist science and technology studies, Ecological feminism or ecofeminism, Girls studies and boys studies, See also, References, Further reading, External links\\\"], [\\\"Feminist literary criticism\\\", 7884, 2360, 8573, 11, 15, 251, 7, 19, 0, 0, 6, 8, 0, [\\\"23.6\\\", 5], 0, [\\\"41.4\\\", 2], 1, 1, 0, 1, [\\\"92.4\\\", 7], [\\\"16.6\\\", 6], \\\"Professional/Academic\\\", [\\\"0.103\\\", 8], [\\\"0.338\\\", 2], [\\\"-0.996\\\", 3], \\\"Slight Bias\\\", 11, \\\"Methods Employed, History and Critics, Modern applications, References, Further reading, External links\\\"], [\\\"Toward a Feminist Theory of the State\\\", 1350, 1149, 1211, 35, 1, 26, 4, 18, 1, 0, 0, 0, 0, [\\\"32.3\\\", 10], 0, [\\\"0.0\\\", 1], 3, 0, 0, 2, [\\\"86.1\\\", 3], [\\\"19.0\\\", 9], \\\"Professional/Academic\\\", [\\\"0.127\\\", 9], [\\\"0.409\\\", 10], [\\\"-0.980\\\", 4], \\\"Slight Bias\\\", 15, \\\"Summary, Reception, Academic reviews, Popular press, References\\\"], [\\\"Feminist sociology\\\", 1101, 2802, 6808, 43, 2, 133, 11, 35, 0, 20, 35, 6, 1, [\\\"23.7\\\", 6], 0, [\\\"84.4\\\", 7], 2, 3, 1, 0, [\\\"83.9\\\", 2], [\\\"14.7\\\", 3], \\\"College Graduate\\\", [\\\"0.083\\\", 5], [\\\"0.404\\\", 9], [\\\"-0.999\\\", 2], \\\"Neutral but Subjective\\\", 11, \\\"History, Feminism and race, Feminism and stratification, Feminism and gender, Feminism and queer theory, Feminist critiques of multiculturalism, Types of feminism, Criticism of feminist sociology, Anti-feminism, References, Further reading\\\"], [\\\"Third-wave feminism\\\", 37900, 4080, 1672, 29, 20, 277, 14, 92, 1, 17, 41, 27, 9, [\\\"18.2\\\", 3], 7, [\\\"85.9\\\", 8], 8, 1, 0, 1, [\\\"95.6\\\", 8], [\\\"13.6\\\", 1], \\\"College Graduate\\\", [\\\"0.088\\\", 6], [\\\"0.376\\\", 6], [\\\"-0.999\\\", 2], \\\"Neutral but Subjective\\\", 13, \\\"Background, Global Influence, Early years, Anita Hill, Riot grrrl, Purpose, Relationship with second wave, Issues, Violence against women, Reproductive rights, Reclaiming derogatory terms, Sexual liberation, Other issues, Criticism, Lack of cohesion, Objection to \\\\\\\"wave construct\\\\\\\", Relationship with women of color, \\\\\\\"Girly\\\\\\\" feminism, Timeline, 1990s, 2000s, Notes, References, Bibliography, Further reading, Suggested listening, External links\\\"], [\\\"Feminism\\\", 120152, 10877, 14353, 53, 104, 201, 39, 348, 3, 56, 183, 62, 24, [\\\"24.9\\\", 8], 23, [\\\"76.8\\\", 5], 10, 6, 1, 1, [\\\"92.4\\\", 7], [\\\"16.2\\\", 5], \\\"Professional/Academic\\\", [\\\"0.092\\\", 7], [\\\"0.351\\\", 4], [\\\"0.960\\\", 7], \\\"Neutral but Subjective\\\", 30, \\\"History, Terminology, Waves, 19th and early 20th centuries, Mid-20th century, Late 20th and early 21st centuries, Third-wave feminism, Standpoint theory, Fourth-wave feminism, Decolonial feminism, Postfeminism, Theory, Movements and ideologies, Liberal feminism, Radical feminism, Materialist ideologies, Other modern feminisms, Ecofeminism, Black and postcolonial ideologies, Social constructionist ideologies, Transgender people, Cultural movements, Demographics, Sexuality, Sex industry, Affirming female sexual autonomy, Science, Biology and gender, Feminist psychology, Culture, Design, Businesses, Visual arts, Literature, Music, Cinema, Politics, Socialism, Fascism, Civil rights movement and anti-racism, Neoliberalism, Societal impact, Civil rights, Jurisprudence, Language, Theology, Patriarchy, Men and masculinity, Reactions, Pro-feminism, Criticism of feminism, Anti-feminism, Secular humanism, See also, Explanatory notes, References, External links, Articles, Multimedia and documents, Books\\\"], [\\\"Gender-critical feminism\\\", 23750, 6855, 43075, 2, 341, 109, 16, 181, 0, 65, 19, 43, 37, [\\\"5.6\\\", 1], 162, [\\\"90.6\\\", 10], 8, 3, 2, 1, [\\\"90.1\\\", 6], [\\\"18.5\\\", 8], \\\"Professional/Academic\\\", [\\\"0.072\\\", 2], [\\\"0.396\\\", 7], [\\\"-1.000\\\", 1], \\\"Neutral but Subjective\\\", 27, \\\"Terminology, Trans-exclusionary radical feminism, Gender-critical feminism, Views, Sex and gender, \\\\\\\"Sex-based rights\\\\\\\", Inclusive language, Socialisation and gender nonconformity, Gender transition, Transgender youth, Intersex conditions, Sexual orientation, Conversion therapy, History, Early history (before 2000), By country, Europe, France, Germany, Asia, China, Japan, Turkey, Analysis, Scholarly analysis, Relationship with feminism, Relationship with the anti-gender movement, Political alliances with conservatives and the far right, Misinformation and disinformation, Controversies, Academic freedom, Conflicts with other feminist and pro-equality groups, Social media, Symbolism and iconography, See also, References, Further reading, External links\\\"]]\", \"keys_to_be_evaluated\": [[\"columnDefs\", 0, \"render\"]]};\n",
              "        new ITable(table, dt_args);\n",
              "    });\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "path = \"/content/feminist_theory_10.csv\" #@param {type:\"string\"}\n",
        "# Read CSV into DataFrame\n",
        "df = pd.read_csv(path)\n",
        "show(df,\n",
        "        scrollX=True,\n",
        "        scrollY=\"600px\",\n",
        "        paging=True,\n",
        "        lengthMenu=[10, 25, 50, 100],\n",
        "        pageLength=25,\n",
        "        buttons=['copy', 'csv', 'excel', 'colvis'],\n",
        "        order=[[1, 'desc']],  # Sort by \"Last 3 Months Views\" descending by default\n",
        "        columnDefs=[{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55pz5tiL0nGp"
      },
      "source": [
        "Ignore these:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi6IBVBwXu7V"
      },
      "source": [
        "Sexology_and_sexuality, psychology, Feminism, Women, etc.\n",
        "List of wiki projects here: https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3iU9TZPB4yhc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from urllib.parse import quote\n",
        "import time\n",
        "import re\n",
        "from IPython.display import display\n",
        "EMAIL = \"amjose05@gmail.com\" #@param {type:\"string\"}\n",
        "import random\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": f\"Wikiproject_article_finder/1.0 (Educational research; {EMAIL}; Python/requests)\"\n",
        "}\n",
        "WIKIPROJECT = \"psychology\" #@param {type:\"string\"}\n",
        "CLASS = \"C-Class\" #@param {type:\"string\"}\n",
        "MAX_ARTICLES = \"0\" #@param {type:\"string\"}\n",
        "try:\n",
        "  MAX_ARTICLES = int(MAX_ARTICLES)  # Try conversion\n",
        "except (ValueError, TypeError):\n",
        "  MAX_ARTICLES = None\n",
        "LANG = \"en\"\n",
        "REQUEST_DELAY = 0.03\n",
        "CHECKPOINT_INTERVAL = 100\n",
        "\n",
        "\n",
        "\n",
        "def get_project_articles(project, klass, MAX_ARTICLES=None):\n",
        "    \"\"\"\n",
        "    Fetch article titles for a given WikiProject and class.\n",
        "    \"\"\"\n",
        "    category = f\"Category:{klass}_{project}_articles\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    print(f\"Fetching from: {category}\")\n",
        "\n",
        "    titles = []\n",
        "    cmcontinue = None\n",
        "    page_count = 0\n",
        "\n",
        "    while True:\n",
        "        page_count += 1\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"list\": \"categorymembers\",\n",
        "            \"cmtitle\": category,\n",
        "            \"cmlimit\": 500,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "        if cmcontinue:\n",
        "            params[\"cmcontinue\"] = cmcontinue\n",
        "\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            print(\"Non-JSON response, retrying...\")\n",
        "            time.sleep(2)\n",
        "            continue\n",
        "\n",
        "        data = r.json()\n",
        "        members = data.get(\"query\", {}).get(\"categorymembers\", [])\n",
        "\n",
        "        print(f\"  Page {page_count}: Found {len(members)} items\")\n",
        "\n",
        "        for p in members:\n",
        "            title = p[\"title\"]\n",
        "            if title.startswith(\"Talk:\"):\n",
        "                article_title = title[5:]\n",
        "                titles.append(article_title)\n",
        "            elif not title.startswith(\"Category:\"):\n",
        "                titles.append(title)\n",
        "\n",
        "            if MAX_ARTICLES and len(titles) >= MAX_ARTICLES:\n",
        "                unique = sorted(set(titles))[:MAX_ARTICLES]\n",
        "                print(f\"Reached limit of {MAX_ARTICLES} articles\")\n",
        "                return unique\n",
        "\n",
        "        cmcontinue = data.get(\"continue\", {}).get(\"cmcontinue\")\n",
        "        if not cmcontinue:\n",
        "            break\n",
        "\n",
        "        time.sleep(REQUEST_DELAY)\n",
        "\n",
        "    unique_titles = sorted(set(titles))\n",
        "    print(f\"Total unique articles found: {len(unique_titles)}\")\n",
        "\n",
        "    return unique_titles\n",
        "\n",
        "def get_article_metadata(title):\n",
        "    \"\"\"\n",
        "    Get basic metadata: days since edit, word count, citation needed count\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": title,\n",
        "        \"redirects\": True,\n",
        "        \"prop\": \"revisions|extracts\",\n",
        "        \"rvprop\": \"content|timestamp\",\n",
        "        \"rvslots\": \"main\",\n",
        "        \"explaintext\": True,\n",
        "        \"exlimit\": 1,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "    r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "    if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "        return 0, 0, 0\n",
        "\n",
        "    data = r.json()\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "\n",
        "    # Calculate days since last edit\n",
        "    last_edit_str = page.get(\"revisions\", [{}])[0].get(\"timestamp\", \"\")\n",
        "    days_since_edit = 0\n",
        "    if last_edit_str:\n",
        "        last_edit = datetime.strptime(last_edit_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        days_since_edit = round((datetime.now(timezone.utc).replace(tzinfo=None) - last_edit).days)\n",
        "\n",
        "    # Word count\n",
        "    extract = page.get(\"extract\", \"\")\n",
        "    word_count = len(extract.split()) if extract else 0\n",
        "\n",
        "    # Count \"citation needed\"\n",
        "    wikitext = page.get(\"revisions\", [{}])[0].get(\"slots\", {}).get(\"main\", {}).get(\"*\", \"\")\n",
        "    citation_needed_count = wikitext.lower().count(\"citation needed\")\n",
        "\n",
        "    return days_since_edit, word_count, citation_needed_count\n",
        "\n",
        "def get_sections(title):\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"parse\",\n",
        "        \"page\": title,\n",
        "        \"prop\": \"sections\",\n",
        "        \"redirects\": 1,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return \"\"\n",
        "        parse_data = r.json().get(\"parse\", {})\n",
        "        if not parse_data:\n",
        "            return \"\"\n",
        "        sections = parse_data.get(\"sections\", [])\n",
        "        section_names = \", \".join(s[\"line\"] for s in sections)\n",
        "        return section_names\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def get_citation_count(title):\n",
        "    \"\"\"\n",
        "    Universal citation counter that handles ALL citation formats:\n",
        "    - Standard <ref> tags\n",
        "    - {{sfn}}, {{sfnp}}, {{sfnm}} (short footnotes with variants)\n",
        "    - {{harv}}, {{harvnb}}, {{harvp}}, etc. (Harvard citations)\n",
        "    - {{r}}, {{rp}} (reference shortcuts)\n",
        "    - {{efn}} (explanatory footnotes)\n",
        "    - {{citation needed}} tags\n",
        "    - List-defined references\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"prop\": \"revisions\",\n",
        "        \"rvprop\": \"content\",\n",
        "        \"rvslots\": \"main\",\n",
        "        \"titles\": title,\n",
        "        \"redirects\": 1,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return 0\n",
        "\n",
        "        data = r.json()\n",
        "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "        page = next(iter(pages.values()), {})\n",
        "\n",
        "        if \"revisions\" not in page:\n",
        "            return 0\n",
        "\n",
        "        content = page.get(\"revisions\", [{}])[0].get(\"slots\", {}).get(\"main\", {}).get(\"*\", \"\")\n",
        "\n",
        "        # Method 1: Count standard <ref> tags (unique named refs + unnamed refs)\n",
        "        named_refs = set()\n",
        "        unnamed_count = 0\n",
        "\n",
        "        ref_pattern = r'<ref(?:\\s+[^>]*)?>'\n",
        "        all_refs = re.findall(ref_pattern, content, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "        for ref in all_refs:\n",
        "            if ref.strip().endswith('/>'):\n",
        "                continue\n",
        "\n",
        "            name_match = re.search(r'name\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', ref, re.IGNORECASE)\n",
        "            if name_match:\n",
        "                named_refs.add(name_match.group(1))\n",
        "            else:\n",
        "                unnamed_count += 1\n",
        "\n",
        "        ref_count = len(named_refs) + unnamed_count\n",
        "\n",
        "        # Method 2: Count ALL sfn variants (sfn, sfnp, sfnm, sfnmp, etc.)\n",
        "        sfn_pattern = r'\\{\\{sfn[a-z]*\\|'\n",
        "        sfn_count = len(re.findall(sfn_pattern, content, re.IGNORECASE))\n",
        "\n",
        "        # Method 3: Count ALL harv variants (harv, harvnb, harvp, harvtxt, etc.)\n",
        "        harv_pattern = r'\\{\\{harv[a-z]*\\|'\n",
        "        harv_count = len(re.findall(harv_pattern, content, re.IGNORECASE))\n",
        "\n",
        "        # Method 4: Count {{r}} and {{rp}} (reference shortcuts)\n",
        "        r_pattern = r'\\{\\{rp?\\|'\n",
        "        r_count = len(re.findall(r_pattern, content, re.IGNORECASE))\n",
        "\n",
        "        # Method 5: Count {{efn}} (explanatory footnotes)\n",
        "        efn_pattern = r'\\{\\{efn[a-z]*\\|'\n",
        "        efn_count = len(re.findall(efn_pattern, content, re.IGNORECASE))\n",
        "\n",
        "        # Method 6: Count list-defined references\n",
        "        ldr_count = 0\n",
        "        ldr_match = re.search(r'\\{\\{reflist\\|refs=(.*?)\\n\\}\\}', content, re.IGNORECASE | re.DOTALL)\n",
        "        if ldr_match:\n",
        "            ldr_content = ldr_match.group(1)\n",
        "            ldr_count = len(re.findall(r'<ref name=', ldr_content, re.IGNORECASE))\n",
        "\n",
        "        # Combine footnote-style citations (sfn + efn count together, as they're often used together)\n",
        "        footnote_count = sfn_count + efn_count\n",
        "\n",
        "        # Use the highest count from all methods\n",
        "        # (articles typically use ONE main citation style)\n",
        "        total_citations = max(ref_count, footnote_count, harv_count, r_count, ldr_count)\n",
        "\n",
        "        return total_citations\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠ Citation error: {e}\")\n",
        "        return 0\n",
        "\n",
        "def get_images_and_categories(title):\n",
        "    \"\"\"\n",
        "    Get image count and category count\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": title,\n",
        "        \"redirects\": True,\n",
        "        \"prop\": \"images|categories\",\n",
        "        \"imlimit\": 500,\n",
        "        \"cllimit\": 500,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return 0, 0\n",
        "\n",
        "        data = r.json()\n",
        "        page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "\n",
        "        images = len(page.get(\"images\", []))\n",
        "        categories = len(page.get(\"categories\", []))\n",
        "\n",
        "        return images, categories\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Images/categories error: {e}\")\n",
        "        return 0, 0\n",
        "\n",
        "def get_edit_statistics(title):\n",
        "    \"\"\"\n",
        "    Get edit statistics: total editors and edits in last year\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": title,\n",
        "        \"redirects\": True,\n",
        "        \"prop\": \"revisions\",\n",
        "        \"rvprop\": \"timestamp|user\",\n",
        "        \"rvlimit\": 500,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return 0, 0\n",
        "\n",
        "        data = r.json()\n",
        "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "        page = next(iter(pages.values()), {})\n",
        "\n",
        "        revisions = page.get(\"revisions\", [])\n",
        "\n",
        "        unique_editors = set()\n",
        "        recent_edits = 0\n",
        "        one_year_ago = datetime.now(timezone.utc) - timedelta(days=365)\n",
        "\n",
        "        for rev in revisions:\n",
        "            user = rev.get(\"user\", \"\")\n",
        "            if user:\n",
        "                unique_editors.add(user)\n",
        "\n",
        "            # Count recent edits (last year)\n",
        "            timestamp_str = rev.get(\"timestamp\", \"\")\n",
        "            if timestamp_str:\n",
        "                timestamp = datetime.strptime(timestamp_str, \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=timezone.utc)\n",
        "                if timestamp >= one_year_ago:\n",
        "                    recent_edits += 1\n",
        "\n",
        "        return len(unique_editors), recent_edits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Edit statistics error: {e}\")\n",
        "        return 0, 0\n",
        "\n",
        "def get_talk_page_size(title):\n",
        "    \"\"\"\n",
        "    Get the size of the talk page in bytes\n",
        "    \"\"\"\n",
        "    url = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"titles\": f\"Talk:{title}\",\n",
        "        \"redirects\": True,\n",
        "        \"prop\": \"revisions\",\n",
        "        \"rvprop\": \"size\",\n",
        "        \"rvlimit\": 1,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return 0\n",
        "\n",
        "        data = r.json()\n",
        "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "        page = next(iter(pages.values()), {})\n",
        "\n",
        "        # Check if page exists (missing pages have negative IDs)\n",
        "        if int(page.get(\"pageid\", -1)) < 0:\n",
        "            return 0\n",
        "\n",
        "        size = page.get(\"revisions\", [{}])[0].get(\"size\", 0)\n",
        "        return size\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Talk page error: {e}\")\n",
        "        return 0\n",
        "\n",
        "def get_pageviews_3mo(title):\n",
        "    end = datetime.now(timezone.utc).replace(tzinfo=None)\n",
        "    start = end - timedelta(days=90)\n",
        "    encoded_title = quote(title.replace(' ', '_'))\n",
        "    url = (\n",
        "        f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/\"\n",
        "        f\"en.wikipedia/all-access/user/\"\n",
        "        f\"{encoded_title}/daily/\"\n",
        "        f\"{start:%Y%m%d}/{end:%Y%m%d}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        if not r.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
        "            return 0\n",
        "        data = r.json()\n",
        "        return sum(d[\"views\"] for d in data.get(\"items\", []))\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Main execution\n",
        "print(\"=\"*60)\n",
        "print(f\"Fetching {CLASS} {WIKIPROJECT} articles from Wikipedia\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "articles = get_project_articles(WIKIPROJECT, CLASS, MAX_ARTICLES)  # Change to None for all\n",
        "\n",
        "if not articles:\n",
        "    print(\"\\nNo articles found.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Processing {len(articles)} articles...\")\n",
        "print(f\"Estimated time: {len(articles) * 6 * REQUEST_DELAY / 60:.1f} - {len(articles) * 6 * 0.5 / 60:.1f} minutes\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "rows = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, title in enumerate(articles, 1):\n",
        "    print(f\"[{i}/{len(articles)}] {title}\")\n",
        "    try:\n",
        "        days_since_edit, word_count, citation_needed = get_article_metadata(title)\n",
        "        sections = get_sections(title)\n",
        "        citations = get_citation_count(title)\n",
        "        views = get_pageviews_3mo(title)\n",
        "        images, categories = get_images_and_categories(title)\n",
        "        num_editors, recent_edits = get_edit_statistics(title)\n",
        "        talk_page_size = get_talk_page_size(title)\n",
        "\n",
        "        rows.append({\n",
        "            \"Article\": title,\n",
        "            \"Days Since Last Edit\": days_since_edit,\n",
        "            \"Word Count\": word_count,\n",
        "            \"Section Names\": sections,\n",
        "            \"Citations\": citations,\n",
        "            \"Citation Needed Count\": citation_needed,\n",
        "            \"Images\": images,\n",
        "            \"Categories\": categories,\n",
        "            \"Total Editors\": num_editors,\n",
        "            \"Edits Last Year\": recent_edits,\n",
        "            \"Talk Page Size (bytes)\": talk_page_size,\n",
        "            \"Last 3 Months Views\": views\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        rows.append({\n",
        "            \"Article\": title,\n",
        "            \"Days Since Last Edit\": 0,\n",
        "            \"Word Count\": 0,\n",
        "            \"Section Names\": \"\",\n",
        "            \"Citations\": 0,\n",
        "            \"Citation Needed Count\": 0,\n",
        "            \"Images\": 0,\n",
        "            \"Categories\": 0,\n",
        "            \"Total Editors\": 0,\n",
        "            \"Edits Last Year\": 0,\n",
        "            \"Talk Page Size (bytes)\": 0,\n",
        "            \"Last 3 Months Views\": 0\n",
        "        })\n",
        "\n",
        "    # Checkpoint saves\n",
        "    if i % CHECKPOINT_INTERVAL == 0:\n",
        "        df_checkpoint = pd.DataFrame(rows)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        checkpoint_file = f\"{WIKIPROJECT}_{CLASS}_{EMAIL}_{MAX_ARTICLES}.csv\"\n",
        "        df_checkpoint.to_csv(checkpoint_file, index=False)\n",
        "        elapsed = time.time() - start_time\n",
        "        remaining = (elapsed / i) * (len(articles) - i)\n",
        "        print(f\"Checkpoint saved: {checkpoint_file}\")\n",
        "        print(f\"Elapsed: {elapsed/60:.1f}min | Estimated remaining: {remaining/60:.1f}min\")\n",
        "\n",
        "    time.sleep(REQUEST_DELAY)\n",
        "\n",
        "# Save final CSV and display dataframe\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows)\n",
        "    #timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{WIKIPROJECT}_{CLASS}_{EMAIL}_{MAX_ARTICLES}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    filename = f\"/content/drive/MyDrive/{WIKIPROJECT}_{CLASS}_{EMAIL}_{MAX_ARTICLES}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    elapsed_total = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Successfully saved {len(df)} articles to: {filename}\")\n",
        "    print(f\"Total time: {elapsed_total/60:.1f} minutes\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Display editable dataframe\n",
        "    print(\"Editable DataFrame:\")\n",
        "    display(df)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Summary statistics:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    numeric_cols = ['Days Since Last Edit', 'Word Count', 'Citations', 'Citation Needed Count',\n",
        "                   'Images', 'Categories', 'Total Editors', 'Edits Last Year',\n",
        "                   'Talk Page Size (bytes)', 'Last 3 Months Views']\n",
        "    print(round(df[numeric_cols].describe(), 1))\n",
        "else:\n",
        "    print(\"\\nNo data to save\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pPWf-puxWKAhrKYk3VVPRoa43gyAVqVN",
      "authorship_tag": "ABX9TyOEL4MGcJeKoqrUAcXHCSUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "048ceffcf80f492588eec520ae966731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf83073b81ca4e0e8a8d9174bc2cb491",
              "IPY_MODEL_66df35dedb7f43a69f3188599b479b1e",
              "IPY_MODEL_0e7d37256e9741e1952e7f75305cc129",
              "IPY_MODEL_35dfc69df4314ce9a64e5921479feef7",
              "IPY_MODEL_01ab5073a5a9416bb8cc5b16d08ac6e1"
            ],
            "layout": "IPY_MODEL_428688f2104540d9870e5b5245c420c9"
          }
        },
        "cf83073b81ca4e0e8a8d9174bc2cb491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322e067c93d9410e97547a4bad525740",
            "placeholder": "​",
            "style": "IPY_MODEL_a3a0013a494b4544a38dc25826c2d94a",
            "value": "<h2>Multi-Path Topic Explorer</h2>"
          }
        },
        "66df35dedb7f43a69f3188599b479b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f40db68760744ee9c1b1a2fede81e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_4d317205deff476696e6ead863d6e317",
            "value": "<p>Discovers related topics from Wikipedia and semantic knowledge graphs.</p>"
          }
        },
        "0e7d37256e9741e1952e7f75305cc129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Topic:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_206b32e4904d48659150bef141089478",
            "placeholder": "Enter a topic",
            "style": "IPY_MODEL_68638704b1bb49278ef2ba99448eabc6",
            "value": ""
          }
        },
        "35dfc69df4314ce9a64e5921479feef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Explore Topic",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c34e8d43237640be82a341cd8a6d0889",
            "style": "IPY_MODEL_24e7bfd1627240d4b47f333c658b0fdc",
            "tooltip": ""
          }
        },
        "01ab5073a5a9416bb8cc5b16d08ac6e1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6fc690dd3c9e4f3ebb45b0e1d6702f89",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "TOPIC EXPLORATION\n",
                  "======================================================================\n",
                  "Exploring: 'Edward O. Wilson'\n",
                  "======================================================================\n",
                  "\n",
                  "Analyzing multiple pathways (30-40 seconds)...\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<div style='font-family: monospace;'><h3>WIKIPEDIA ARTICLES FOUND</h3><hr><ol><li><a href=\"https://en.wikipedia.org/wiki/Epic_of_evolution\" target=\"_blank\">Epic of evolution</a></li><li><a href=\"https://en.wikipedia.org/wiki/Corina_Tarnita\" target=\"_blank\">Corina Tarnita</a></li><li><a href=\"https://en.wikipedia.org/wiki/American_Computer_&_Robotics_Museum\" target=\"_blank\">American Computer & Robotics Museum</a></li></ol><h3>PATHWAY 1: Based on 'Epic of evolution'</h3><hr><h4>Editor-curated related topics:</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Big_History\" target=\"_blank\">Big History</a></li><li><a href=\"https://en.wikipedia.org/wiki/Cosmic_Evolution_(book)\" target=\"_blank\">Cosmic Evolution (book)</a></li><li><a href=\"https://en.wikipedia.org/wiki/Evolution_as_theory_and_fact\" target=\"_blank\">Evolution as theory and fact</a></li><li><a href=\"https://en.wikipedia.org/wiki/Level_of_support_for_evolution\" target=\"_blank\">Level of support for evolution</a></li><li><a href=\"https://en.wikipedia.org/wiki/Modern_synthesis_(20th_century)\" target=\"_blank\">Modern synthesis (20th century)</a></li><li><a href=\"https://en.wikipedia.org/wiki/National_Center_for_Science_Education\" target=\"_blank\">National Center for Science Education</a></li><li><a href=\"https://en.wikipedia.org/wiki/Natural_history\" target=\"_blank\">Natural history</a></li><li><a href=\"https://en.wikipedia.org/wiki/Objections_to_evolution\" target=\"_blank\">Objections to evolution</a></li></ol><h4>Related concepts from article:</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Neo-Darwinism\" target=\"_blank\">Neo-Darwinism</a></li><li><a href=\"https://en.wikipedia.org/wiki/Universal_Darwinism\" target=\"_blank\">Universal Darwinism</a></li><li><a href=\"https://en.wikipedia.org/wiki/Institute_for_Creation_Research\" target=\"_blank\">Institute for Creation Research</a></li><li><a href=\"https://en.wikipedia.org/wiki/Cultural_studies\" target=\"_blank\">Cultural studies</a></li><li><a href=\"https://en.wikipedia.org/wiki/United_States_National_Academy_of_Sciences\" target=\"_blank\">United States National Academy of Sciences</a></li><li><a href=\"https://en.wikipedia.org/wiki/American_Association_for_the_Advancement_of_Science\" target=\"_blank\">American Association for the Advancement of Science</a></li><li><a href=\"https://en.wikipedia.org/wiki/Religious_naturalism\" target=\"_blank\">Religious naturalism</a></li><li><a href=\"https://en.wikipedia.org/wiki/Creationism\" target=\"_blank\">Creationism</a></li><li><a href=\"https://en.wikipedia.org/wiki/Institute_on_Religion_in_an_Age_of_Science\" target=\"_blank\">Institute on Religion in an Age of Science</a></li><li><a href=\"https://en.wikipedia.org/wiki/Religious_studies\" target=\"_blank\">Religious studies</a></li></ol><h4>Similar topics (same categories):</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Adaptation\" target=\"_blank\">Adaptation</a></li><li><a href=\"https://en.wikipedia.org/wiki/Hologenome_theory_of_evolution\" target=\"_blank\">Hologenome theory of evolution</a></li><li><a href=\"https://en.wikipedia.org/wiki/Cosmology\" target=\"_blank\">Cosmology</a></li><li><a href=\"https://en.wikipedia.org/wiki/Evolutionary_tinkering\" target=\"_blank\">Evolutionary tinkering</a></li><li><a href=\"https://en.wikipedia.org/wiki/Fisheries-induced_evolution\" target=\"_blank\">Fisheries-induced evolution</a></li><li><a href=\"https://en.wikipedia.org/wiki/Hominization\" target=\"_blank\">Hominization</a></li><li><a href=\"https://en.wikipedia.org/wiki/Big_Bounce\" target=\"_blank\">Big Bounce</a></li><li><a href=\"https://en.wikipedia.org/wiki/Barnes–Hut_simulation\" target=\"_blank\">Barnes–Hut simulation</a></li></ol><h3>PATHWAY 2: Based on 'Corina Tarnita'</h3><hr><h4>Related concepts from article:</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Alfred_P._Sloan_Research_Fellowship\" target=\"_blank\">Alfred P. Sloan Research Fellowship</a></li><li><a href=\"https://en.wikipedia.org/wiki/Doctor_of_Philosophy\" target=\"_blank\">Doctor of Philosophy</a></li><li><a href=\"https://en.wikipedia.org/wiki/Materials_science\" target=\"_blank\">Materials science</a></li><li><a href=\"https://en.wikipedia.org/wiki/Microorganism\" target=\"_blank\">Microorganism</a></li><li><a href=\"https://en.wikipedia.org/wiki/National_Academy_of_Sciences\" target=\"_blank\">National Academy of Sciences</a></li></ol><h4>Similar topics (same categories):</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Irwin_Abrams\" target=\"_blank\">Irwin Abrams</a></li><li><a href=\"https://en.wikipedia.org/wiki/Dan_Abramovich\" target=\"_blank\">Dan Abramovich</a></li><li><a href=\"https://en.wikipedia.org/wiki/Mitra_Abbaspour\" target=\"_blank\">Mitra Abbaspour</a></li><li><a href=\"https://en.wikipedia.org/wiki/Edwin_Plimpton_Adams\" target=\"_blank\">Edwin Plimpton Adams</a></li><li><a href=\"https://en.wikipedia.org/wiki/Philip_Stanley_Abbot\" target=\"_blank\">Philip Stanley Abbot</a></li><li><a href=\"https://en.wikipedia.org/wiki/Virginia_Abernethy\" target=\"_blank\">Virginia Abernethy</a></li><li><a href=\"https://en.wikipedia.org/wiki/Edward_Augustus_Ackerman\" target=\"_blank\">Edward Augustus Ackerman</a></li><li><a href=\"https://en.wikipedia.org/wiki/David_Aberle\" target=\"_blank\">David Aberle</a></li></ol><h3>PATHWAY 3: Based on 'American Computer & Robotics Museum'</h3><hr><h4>Editor-curated related topics:</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Computer_museum\" target=\"_blank\">Computer museum</a></li></ol><h4>Related concepts from article:</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/Antikythera_Mechanism\" target=\"_blank\">Antikythera Mechanism</a></li><li><a href=\"https://en.wikipedia.org/wiki/Approach_and_Landing_Tests\" target=\"_blank\">Approach and Landing Tests</a></li></ol><h4>Similar topics (same categories):</h4><ol><li><a href=\"https://en.wikipedia.org/wiki/National_Videogame_Museum_(United_States)\" target=\"_blank\">National Videogame Museum (United States)</a></li><li><a href=\"https://en.wikipedia.org/wiki/International_Slide_Rule_Museum\" target=\"_blank\">International Slide Rule Museum</a></li><li><a href=\"https://en.wikipedia.org/wiki/Carter_County_Museum\" target=\"_blank\">Carter County Museum</a></li><li><a href=\"https://en.wikipedia.org/wiki/KTMF\" target=\"_blank\">KTMF</a></li><li><a href=\"https://en.wikipedia.org/wiki/Montana_State_Prison\" target=\"_blank\">Montana State Prison</a></li><li><a href=\"https://en.wikipedia.org/wiki/Museum_of_the_Rockies\" target=\"_blank\">Museum of the Rockies</a></li><li><a href=\"https://en.wikipedia.org/wiki/Grant–Kohrs_Ranch_National_Historic_Site\" target=\"_blank\">Grant–Kohrs Ranch National Historic Site</a></li><li><a href=\"https://en.wikipedia.org/wiki/World_Museum_of_Mining\" target=\"_blank\">World Museum of Mining</a></li></ol><hr><p><strong>Exploration complete. Click any link to open the Wikipedia article.</strong></p></div>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "428688f2104540d9870e5b5245c420c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322e067c93d9410e97547a4bad525740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a0013a494b4544a38dc25826c2d94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f40db68760744ee9c1b1a2fede81e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d317205deff476696e6ead863d6e317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206b32e4904d48659150bef141089478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "500px"
          }
        },
        "68638704b1bb49278ef2ba99448eabc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "100px"
          }
        },
        "c34e8d43237640be82a341cd8a6d0889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "40px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "200px"
          }
        },
        "24e7bfd1627240d4b47f333c658b0fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6fc690dd3c9e4f3ebb45b0e1d6702f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}